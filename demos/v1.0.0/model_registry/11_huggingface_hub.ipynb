{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Header and Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from utils.notebook_utils import display_header, display_toc, check_dependency, conclusion_box\n",
    "from utils.system_info import display_system_info\n",
    "from utils.benchmark import Benchmark, BenchmarkResult, ComparisonTable\n",
    "from utils.charts import setup_style, bar_comparison, throughput_comparison, COLORS\n",
    "\n",
    "display_header('Model Registry Comparison', 'SynaDB vs Hugging Face Hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Table of Contents\n",
    "sections = [\n",
    "    ('Introduction', 'introduction'),\n",
    "    ('Setup', 'setup'),\n",
    "    ('Transformer Model Storage', 'transformer-storage'),\n",
    "    ('Load Time Comparison', 'load-time'),\n",
    "    ('Version Management', 'version-management'),\n",
    "    ('Fine-tuned Models', 'fine-tuned'),\n",
    "    ('Offline Usage', 'offline'),\n",
    "    ('Results Summary', 'results'),\n",
    "    ('Conclusions', 'conclusions'),\n",
    "]\n",
    "display_toc(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Introduction <a id=\"introduction\"></a>\n",
    "\n",
    "This notebook compares **SynaDB's ModelRegistry** against **Hugging Face Hub** for transformer model storage.\n",
    "\n",
    "| System | Type | Key Features |\n",
    "|--------|------|-------------|\n",
    "| **SynaDB** | Local/Embedded | Single-file, offline-first, SHA-256 checksums |\n",
    "| **Hugging Face Hub** | Cloud | Largest model repository, community sharing, model cards |\n",
    "\n",
    "### What We'll Compare\n",
    "\n",
    "- **Transformer model storage** - Saving and loading model weights\n",
    "- **Load time** - Local SynaDB vs HF Hub download\n",
    "- **Version management** - Local versioning vs Hub revisions\n",
    "- **Fine-tuned models** - Storing custom model weights\n",
    "- **Offline usage** - Air-gapped environment support\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **SynaDB**: Local development, edge deployment, air-gapped environments\n",
    "- **HF Hub**: Model sharing, community collaboration, cloud deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: System Info\n",
    "display_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup <a id=\"setup\"></a>\n",
    "\n",
    "Let's set up our test environment for model storage comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Check Dependencies and Imports\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for SynaDB\n",
    "HAS_SYNADB = check_dependency('synadb', 'pip install synadb')\n",
    "\n",
    "# Check for Hugging Face Hub\n",
    "HAS_HF_HUB = check_dependency('huggingface_hub', 'pip install huggingface_hub')\n",
    "\n",
    "# Check for transformers (optional, for real model tests)\n",
    "HAS_TRANSFORMERS = check_dependency('transformers', 'pip install transformers')\n",
    "\n",
    "# Apply consistent styling\n",
    "setup_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Configuration\n",
    "# Test configuration\n",
    "SEED = 42\n",
    "NUM_VERSIONS = 5  # Number of model versions to test\n",
    "\n",
    "# Simulated model sizes (in MB)\n",
    "# Real transformer models: BERT-base ~440MB, GPT-2 ~500MB, etc.\n",
    "SIMULATED_MODEL_SIZE_MB = 50  # Smaller for faster testing\n",
    "\n",
    "print('Test Configuration:')\n",
    "print(f'  Simulated model size: {SIMULATED_MODEL_SIZE_MB}MB')\n",
    "print(f'  Number of versions: {NUM_VERSIONS}')\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Create Temp Directory\n",
    "temp_dir = tempfile.mkdtemp(prefix='synadb_hf_benchmark_')\n",
    "print(f'Using temp directory: {temp_dir}')\n",
    "\n",
    "# Paths\n",
    "synadb_path = os.path.join(temp_dir, 'synadb_models.db')\n",
    "hf_cache_path = os.path.join(temp_dir, 'hf_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Generate Simulated Model Data\n",
    "# Generate simulated transformer model weights\n",
    "# In practice, these would be actual PyTorch state_dict or safetensors\n",
    "\n",
    "def generate_model_weights(size_mb, version):\n",
    "    \"\"\"Generate simulated model weights with version-specific variations.\"\"\"\n",
    "    np.random.seed(SEED + version)\n",
    "    return np.random.bytes(size_mb * 1024 * 1024)\n",
    "\n",
    "# Generate multiple versions\n",
    "model_versions = {}\n",
    "for v in range(NUM_VERSIONS):\n",
    "    model_versions[v] = generate_model_weights(SIMULATED_MODEL_SIZE_MB, v)\n",
    "    print(f'\u2713 Generated model version {v+1} ({SIMULATED_MODEL_SIZE_MB}MB)')\n",
    "\n",
    "# Model metadata (simulating HF model card info)\n",
    "model_metadata = {\n",
    "    'model_type': 'bert',\n",
    "    'hidden_size': 768,\n",
    "    'num_attention_heads': 12,\n",
    "    'num_hidden_layers': 12,\n",
    "    'vocab_size': 30522,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udd16 Transformer Model Storage <a id=\"transformer-storage\"></a>\n",
    "\n",
    "Comparing how each system stores transformer model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: SynaDB Transformer Storage\n",
    "synadb_save_times = []\n",
    "synadb_registry = None\n",
    "\n",
    "if HAS_SYNADB:\n",
    "    from synadb import ModelRegistry\n",
    "    \n",
    "    print('Storing transformer models in SynaDB...')\n",
    "    synadb_registry = ModelRegistry(synadb_path)\n",
    "    \n",
    "    for v in range(NUM_VERSIONS):\n",
    "        # Time model save\n",
    "        start = time.perf_counter()\n",
    "        version_info = synadb_registry.save_model(\n",
    "            'bert-base-custom',\n",
    "            model_versions[v],\n",
    "            {**model_metadata, 'fine_tuned_epoch': str(v * 10)}\n",
    "        )\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        synadb_save_times.append(elapsed)\n",
    "        print(f'  v{v+1}: {elapsed:.2f}ms')\n",
    "    \n",
    "    throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_save_times)\n",
    "    print(f'\\n\u2713 Saved {NUM_VERSIONS} versions')\n",
    "    print(f'  Mean: {np.mean(synadb_save_times):.2f}ms')\n",
    "    print(f'  Throughput: {throughput:.1f} MB/s')\n",
    "else:\n",
    "    print('\u26a0\ufe0f SynaDB not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: HF Hub Storage Pattern (Simulated)\n",
    "hf_save_times = []\n",
    "\n",
    "# Note: Actual HF Hub upload requires authentication and network\n",
    "# We simulate the local file operations that HF Hub performs\n",
    "\n",
    "print('Simulating Hugging Face Hub storage pattern...')\n",
    "os.makedirs(hf_cache_path, exist_ok=True)\n",
    "\n",
    "for v in range(NUM_VERSIONS):\n",
    "    # Simulate HF Hub's local caching behavior\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # HF Hub stores models in a specific directory structure\n",
    "    model_dir = os.path.join(hf_cache_path, f'models--bert-base-custom', f'snapshots', f'v{v}')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Write model weights (simulating safetensors or pytorch_model.bin)\n",
    "    model_file = os.path.join(model_dir, 'pytorch_model.bin')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        f.write(model_versions[v])\n",
    "    \n",
    "    # Write config (simulating config.json)\n",
    "    import json\n",
    "    config_file = os.path.join(model_dir, 'config.json')\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(model_metadata, f)\n",
    "    \n",
    "    elapsed = (time.perf_counter() - start) * 1000\n",
    "    hf_save_times.append(elapsed)\n",
    "    print(f'  v{v+1}: {elapsed:.2f}ms')\n",
    "\n",
    "throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(hf_save_times)\n",
    "print(f'\\n\u2713 Saved {NUM_VERSIONS} versions (local cache simulation)')\n",
    "print(f'  Mean: {np.mean(hf_save_times):.2f}ms')\n",
    "print(f'  Throughput: {throughput:.1f} MB/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Storage Comparison Visualization\n",
    "save_throughput = {}\n",
    "\n",
    "if synadb_save_times:\n",
    "    save_throughput['SynaDB'] = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_save_times)\n",
    "\n",
    "if hf_save_times:\n",
    "    save_throughput['HF Hub (local)'] = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(hf_save_times)\n",
    "\n",
    "if save_throughput:\n",
    "    fig = throughput_comparison(\n",
    "        save_throughput,\n",
    "        title=f'Model Storage Throughput ({SIMULATED_MODEL_SIZE_MB}MB models)',\n",
    "        ylabel='MB/second'\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u23f1\ufe0f Load Time Comparison <a id=\"load-time\"></a>\n",
    "\n",
    "Comparing local load times vs network download times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: SynaDB Load Time\n",
    "synadb_load_times = []\n",
    "\n",
    "if HAS_SYNADB and synadb_registry:\n",
    "    print('Benchmarking SynaDB model load...')\n",
    "    \n",
    "    for v in range(1, NUM_VERSIONS + 1):\n",
    "        # Time model load with checksum verification\n",
    "        start = time.perf_counter()\n",
    "        data, info = synadb_registry.load_model('bert-base-custom', version=v)\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        synadb_load_times.append(elapsed)\n",
    "        print(f'  v{v}: {elapsed:.2f}ms (verified)')\n",
    "    \n",
    "    throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_load_times)\n",
    "    print(f'\\n\u2713 Loaded {NUM_VERSIONS} versions')\n",
    "    print(f'  Mean: {np.mean(synadb_load_times):.2f}ms')\n",
    "    print(f'  Throughput: {throughput:.1f} MB/s')\n",
    "else:\n",
    "    print('\u26a0\ufe0f SynaDB not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: HF Hub Load Time (Local Cache)\n",
    "hf_load_times = []\n",
    "\n",
    "print('Benchmarking HF Hub local cache load...')\n",
    "\n",
    "for v in range(NUM_VERSIONS):\n",
    "    model_file = os.path.join(hf_cache_path, f'models--bert-base-custom', f'snapshots', f'v{v}', 'pytorch_model.bin')\n",
    "    \n",
    "    if os.path.exists(model_file):\n",
    "        start = time.perf_counter()\n",
    "        with open(model_file, 'rb') as f:\n",
    "            data = f.read()\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        hf_load_times.append(elapsed)\n",
    "        print(f'  v{v+1}: {elapsed:.2f}ms')\n",
    "\n",
    "if hf_load_times:\n",
    "    throughput = SIMULATED_MODEL_SIZE_MB * len(hf_load_times) * 1000 / sum(hf_load_times)\n",
    "    print(f'\\n\u2713 Loaded {len(hf_load_times)} versions from cache')\n",
    "    print(f'  Mean: {np.mean(hf_load_times):.2f}ms')\n",
    "    print(f'  Throughput: {throughput:.1f} MB/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Load Time Comparison\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Estimated HF Hub download times (based on typical network speeds)\n",
    "# Assuming 50Mbps connection for a 50MB model\n",
    "estimated_download_time_ms = SIMULATED_MODEL_SIZE_MB * 8 / 50 * 1000  # ~8 seconds\n",
    "\n",
    "# Format values safely (handle empty lists)\n",
    "synadb_load_str = f'{np.mean(synadb_load_times):.0f}' if synadb_load_times else 'N/A'\n",
    "hf_load_str = f'{np.mean(hf_load_times):.0f}' if hf_load_times else 'N/A'\n",
    "\n",
    "load_comparison = f'''\n",
    "### Load Time Comparison\n",
    "\n",
    "| Scenario | SynaDB | HF Hub (cached) | HF Hub (download) |\n",
    "|----------|--------|-----------------|-------------------|\n",
    "| **First load** | {synadb_load_str}ms | {hf_load_str}ms | ~{estimated_download_time_ms:.0f}ms* |\n",
    "| **Cached load** | {synadb_load_str}ms | {hf_load_str}ms | {hf_load_str}ms |\n",
    "| **Checksum verification** | \u2705 Automatic | \u274c None | \u274c None |\n",
    "\n",
    "*Estimated for {SIMULATED_MODEL_SIZE_MB}MB model on 50Mbps connection\n",
    "\n",
    "**Key Insight:** SynaDB provides consistent, fast load times with built-in integrity verification.\n",
    "HF Hub requires network access for first load, then caches locally.\n",
    "'''\n",
    "display(Markdown(load_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Version Management <a id=\"version-management\"></a>\n",
    "\n",
    "Comparing version management approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: SynaDB Version Management\n",
    "if HAS_SYNADB and synadb_registry:\n",
    "    print('SynaDB Version Management')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # List versions\n",
    "    versions = synadb_registry.list_versions('bert-base-custom')\n",
    "    print(f'\\nModel: bert-base-custom')\n",
    "    print(f'Total versions: {len(versions)}')\n",
    "    \n",
    "    print('\\nVersion History:')\n",
    "    for v in versions:\n",
    "        print(f'  v{v.version}: {v.stage}')\n",
    "        print(f'    Checksum: {v.checksum[:24]}...')\n",
    "else:\n",
    "    print('\u26a0\ufe0f SynaDB not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Version Management Comparison\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "version_comparison = '''\n",
    "### Version Management Comparison\n",
    "\n",
    "| Feature | SynaDB | Hugging Face Hub |\n",
    "|---------|--------|------------------|\n",
    "| **Version identifier** | Sequential numbers | Git commit hashes |\n",
    "| **Version listing** | `list_versions()` | `list_repo_refs()` |\n",
    "| **Load specific version** | `load_model(name, version=N)` | `revision=\"commit_hash\"` |\n",
    "| **Metadata per version** | \u2705 Built-in | \u2705 Model cards |\n",
    "| **Offline versioning** | \u2705 Full support | \u274c Requires network |\n",
    "| **Private versions** | \u2705 Local only | \u2705 Private repos |\n",
    "\n",
    "**SynaDB Approach:**\n",
    "```python\n",
    "# Simple sequential versioning\n",
    "registry.save_model(\"my-model\", weights, metadata)  # Auto v1, v2, v3...\n",
    "data, info = registry.load_model(\"my-model\", version=2)\n",
    "```\n",
    "\n",
    "**HF Hub Approach:**\n",
    "```python\n",
    "# Git-based versioning\n",
    "model = AutoModel.from_pretrained(\"user/model\", revision=\"abc123\")\n",
    "```\n",
    "'''\n",
    "display(Markdown(version_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Fine-tuned Models <a id=\"fine-tuned\"></a>\n",
    "\n",
    "Demonstrating storage of fine-tuned model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Fine-tuned Model Storage Demo\n",
    "if HAS_SYNADB and synadb_registry:\n",
    "    print('Storing Fine-tuned Models in SynaDB')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    # Simulate fine-tuning iterations\n",
    "    fine_tune_metadata = [\n",
    "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.92', 'epochs': '3'},\n",
    "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.94', 'epochs': '5'},\n",
    "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.95', 'epochs': '10'},\n",
    "    ]\n",
    "    \n",
    "    print('\\nSaving fine-tuned checkpoints...')\n",
    "    for i, meta in enumerate(fine_tune_metadata):\n",
    "        # Generate slightly different weights for each checkpoint\n",
    "        weights = generate_model_weights(10, 100 + i)  # 10MB for faster demo\n",
    "        \n",
    "        version = synadb_registry.save_model(\n",
    "            'bert-sentiment-finetuned',\n",
    "            weights,\n",
    "            meta\n",
    "        )\n",
    "        print(f'  Checkpoint {i+1}: accuracy={meta[\"accuracy\"]}, epochs={meta[\"epochs\"]}')\n",
    "    \n",
    "    # Promote best model to production\n",
    "    print('\\n\\nPromoting best model (v3) to Production...')\n",
    "    synadb_registry.set_stage('bert-sentiment-finetuned', 3, 'Production')\n",
    "    \n",
    "    # Get production model\n",
    "    prod = synadb_registry.get_production('bert-sentiment-finetuned')\n",
    "    if prod:\n",
    "        print(f'  \u2713 Production model: v{prod.version}')\n",
    "        print(f'  \u2713 Checksum: {prod.checksum[:24]}...')\n",
    "else:\n",
    "    print('\u26a0\ufe0f SynaDB not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23: Fine-tuned Model Comparison\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "finetune_comparison = '''\n",
    "### Fine-tuned Model Storage Comparison\n",
    "\n",
    "| Feature | SynaDB | Hugging Face Hub |\n",
    "|---------|--------|------------------|\n",
    "| **Store checkpoints** | \u2705 `save_model()` | \u2705 `push_to_hub()` |\n",
    "| **Track training metadata** | \u2705 Built-in | \u2705 Model cards |\n",
    "| **Compare versions** | \u2705 `list_versions()` | \u2705 Hub UI |\n",
    "| **Promote to production** | \u2705 `set_stage()` | \u26a0\ufe0f Manual tags |\n",
    "| **Offline fine-tuning** | \u2705 Full support | \u274c Requires network to push |\n",
    "| **Private storage** | \u2705 Local only | \u2705 Private repos (paid) |\n",
    "\n",
    "**Best Practice:** Use SynaDB for local development and checkpointing,\n",
    "then push final models to HF Hub for sharing.\n",
    "'''\n",
    "display(Markdown(finetune_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0c Offline Usage <a id=\"offline\"></a>\n",
    "\n",
    "Demonstrating SynaDB's advantage in air-gapped environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Offline Usage Demonstration\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "offline_demo = '''\n",
    "### Offline Usage Comparison\n",
    "\n",
    "| Scenario | SynaDB | Hugging Face Hub |\n",
    "|----------|--------|------------------|\n",
    "| **Air-gapped environment** | \u2705 Full functionality | \u274c No access |\n",
    "| **Edge deployment** | \u2705 Single file | \u26a0\ufe0f Pre-download required |\n",
    "| **No internet** | \u2705 Works perfectly | \u274c Cache only |\n",
    "| **Secure environments** | \u2705 No network calls | \u26a0\ufe0f Firewall issues |\n",
    "| **Reproducibility** | \u2705 Checksums | \u26a0\ufe0f Network-dependent |\n",
    "\n",
    "### SynaDB Offline Workflow\n",
    "\n",
    "```python\n",
    "# Works anywhere - no network required\n",
    "from synadb import ModelRegistry\n",
    "\n",
    "# Single file contains all models and versions\n",
    "registry = ModelRegistry(\"models.db\")\n",
    "\n",
    "# Save model\n",
    "registry.save_model(\"my-model\", weights, metadata)\n",
    "\n",
    "# Load with integrity verification\n",
    "data, info = registry.load_model(\"my-model\")\n",
    "# Checksum automatically verified!\n",
    "```\n",
    "\n",
    "### HF Hub Offline Workflow\n",
    "\n",
    "```python\n",
    "# Requires pre-downloading models\n",
    "from transformers import AutoModel\n",
    "\n",
    "# First: Download while online\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.save_pretrained(\"./local_model\")\n",
    "\n",
    "# Later: Load from local cache\n",
    "model = AutoModel.from_pretrained(\"./local_model\", local_files_only=True)\n",
    "```\n",
    "'''\n",
    "display(Markdown(offline_demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 26: Storage Size Comparison\n",
    "def get_dir_size(path):\n",
    "    \"\"\"Get total size of a directory in bytes.\"\"\"\n",
    "    total = 0\n",
    "    if os.path.isfile(path):\n",
    "        return os.path.getsize(path)\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total += os.path.getsize(fp)\n",
    "    return total\n",
    "\n",
    "def count_files(path):\n",
    "    \"\"\"Count files in a directory.\"\"\"\n",
    "    if os.path.isfile(path):\n",
    "        return 1\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    count = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        count += len(filenames)\n",
    "    return count\n",
    "\n",
    "print('Storage Comparison')\n",
    "print('=' * 60)\n",
    "\n",
    "# SynaDB\n",
    "if os.path.exists(synadb_path):\n",
    "    size = get_dir_size(synadb_path)\n",
    "    files = count_files(synadb_path)\n",
    "    print(f'SynaDB: {size / (1024 * 1024):.2f} MB ({files} file)')\n",
    "\n",
    "# HF Cache\n",
    "if os.path.exists(hf_cache_path):\n",
    "    size = get_dir_size(hf_cache_path)\n",
    "    files = count_files(hf_cache_path)\n",
    "    print(f'HF Cache: {size / (1024 * 1024):.2f} MB ({files} files)')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('\\nNote: SynaDB stores everything in a single portable file.')\n",
    "print('HF Hub uses a complex directory structure with many files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Results Summary <a id=\"results\"></a>\n",
    "\n",
    "Summarizing the comparison between SynaDB and Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: Results Summary\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "summary = '''\n",
    "### Feature Comparison Summary\n",
    "\n",
    "| Feature | SynaDB | Hugging Face Hub |\n",
    "|---------|--------|------------------|\n",
    "| **Storage type** | Single file | Cloud + local cache |\n",
    "| **Offline support** | \u2705 Full | \u26a0\ufe0f Cache only |\n",
    "| **Integrity verification** | \u2705 SHA-256 | \u274c None |\n",
    "| **Version management** | \u2705 Sequential | \u2705 Git-based |\n",
    "| **Stage management** | \u2705 Built-in | \u26a0\ufe0f Manual tags |\n",
    "| **Community sharing** | \u274c Local only | \u2705 Excellent |\n",
    "| **Model discovery** | \u274c None | \u2705 Hub search |\n",
    "| **Pre-trained models** | \u274c None | \u2705 Thousands |\n",
    "| **Setup complexity** | \u2705 Zero config | \u26a0\ufe0f Auth required |\n",
    "| **Cost** | \u2705 Free | \u26a0\ufe0f Paid for private |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "**Use SynaDB when:**\n",
    "- Developing locally without network\n",
    "- Deploying to edge devices\n",
    "- Working in air-gapped environments\n",
    "- Need integrity verification\n",
    "- Want simple, portable storage\n",
    "\n",
    "**Use HF Hub when:**\n",
    "- Sharing models with the community\n",
    "- Using pre-trained models\n",
    "- Collaborating with teams\n",
    "- Need model cards and documentation\n",
    "- Want cloud-based storage\n",
    "'''\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Performance Summary Chart\n",
    "# Create comparison visualization\n",
    "categories = ['Offline', 'Integrity', 'Simplicity', 'Sharing', 'Discovery']\n",
    "synadb_scores = [1.0, 1.0, 1.0, 0.0, 0.0]\n",
    "hf_scores = [0.3, 0.0, 0.5, 1.0, 1.0]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, synadb_scores, width, label='SynaDB', color=COLORS['synadb'])\n",
    "bars2 = ax.bar(x + width/2, hf_scores, width, label='HF Hub', color=COLORS['competitor'])\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('SynaDB vs Hugging Face Hub - Feature Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.set_ylim(0, 1.2)\n",
    "ax.legend()\n",
    "ax.set_yticks([0, 0.5, 1])\n",
    "ax.set_yticklabels(['None', 'Partial', 'Full'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Conclusions <a id=\"conclusions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 31: Conclusions\n",
    "conclusion_box(\n",
    "    title='Key Takeaways',\n",
    "    points=[\n",
    "        'SynaDB excels for local, offline, and edge deployment scenarios',\n",
    "        'SHA-256 checksums provide strong integrity guarantees',\n",
    "        'Single-file storage simplifies deployment and backup',\n",
    "        'HF Hub is unmatched for community sharing and pre-trained models',\n",
    "        'Both tools can complement each other in a workflow',\n",
    "        'Use SynaDB for development, HF Hub for distribution'\n",
    "    ],\n",
    "    summary='SynaDB and HF Hub serve different needs - use both for a complete workflow.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32: Cleanup\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'\u2713 Cleaned up temp directory: {temp_dir}')\n",
    "except Exception as e:\n",
    "    print(f'\u26a0\ufe0f Could not clean up: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore [LLM Framework integrations](../llm_frameworks/) for RAG applications\n",
    "- Check out [End-to-End Pipeline](../specialized/18_end_to_end_pipeline.ipynb) for complete ML workflows\n",
    "- See [GPU Performance](../specialized/15_gpu_performance.ipynb) for high-performance training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}