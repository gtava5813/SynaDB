#!/usr/bin/env python3
"""Generate the model registry comparison notebooks."""

import json

def create_code_cell(source):
    """Create a code cell."""
    return {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": source if isinstance(source, list) else [source]
    }

def create_markdown_cell(source):
    """Create a markdown cell."""
    return {
        "cell_type": "markdown",
        "metadata": {},
        "source": source if isinstance(source, list) else [source]
    }

def generate_10_mlflow_dvc():
    """Generate the MLflow/DVC comparison notebook."""
    cells = []
    
    # Cell 1: Header and Setup
    cells.append(create_code_cell([
        "# Cell 1: Header and Setup\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from utils.notebook_utils import display_header, display_toc, check_dependency, conclusion_box\n",
        "from utils.system_info import display_system_info\n",
        "from utils.benchmark import Benchmark, BenchmarkResult, ComparisonTable\n",
        "from utils.charts import setup_style, bar_comparison, throughput_comparison, COLORS\n",
        "\n",
        "display_header('Model Registry Comparison', 'SynaDB vs MLflow Model Registry vs DVC')"
    ]))
    
    # Cell 2: Table of Contents
    cells.append(create_code_cell([
        "# Cell 2: Table of Contents\n",
        "sections = [\n",
        "    ('Introduction', 'introduction'),\n",
        "    ('Setup', 'setup'),\n",
        "    ('Benchmark: Model Save/Load', 'benchmark-save-load'),\n",
        "    ('Demo: Version Management', 'demo-version'),\n",
        "    ('Demo: Stage Promotion', 'demo-stage'),\n",
        "    ('Demo: Rollback', 'demo-rollback'),\n",
        "    ('Integrity Guarantees', 'integrity'),\n",
        "    ('Results Summary', 'results'),\n",
        "    ('Conclusions', 'conclusions'),\n",
        "]\n",
        "display_toc(sections)"
    ]))
    
    # Cell 3: Introduction
    cells.append(create_markdown_cell([
        "## üìå Introduction <a id=\"introduction\"></a>\n",
        "\n",
        "This notebook compares **SynaDB's ModelRegistry** against **MLflow Model Registry** and **DVC**.\n",
        "\n",
        "| System | Type | Key Features |\n",
        "|--------|------|-------------|\n",
        "| **SynaDB** | Embedded | Single-file, SHA-256 checksums, stage management |\n",
        "| **MLflow** | Server-based | Industry standard, rich UI, model serving |\n",
        "| **DVC** | Git-based | Version control for data/models, remote storage |\n",
        "\n",
        "### What We'll Measure\n",
        "\n",
        "- **Model save/load** latency and throughput\n",
        "- **Version management** capabilities\n",
        "- **Stage promotion** workflows\n",
        "- **Rollback** operations\n",
        "- **Integrity guarantees** (checksum verification)"
    ]))
    
    # Cell 4: System Info
    cells.append(create_code_cell([
        "# Cell 4: System Info\n",
        "display_system_info()"
    ]))
    
    return cells

if __name__ == "__main__":
    cells = generate_10_mlflow_dvc()
    print(f"Generated {len(cells)} cells")


def add_setup_cells(cells):
    """Add setup cells to the notebook."""
    # Setup markdown
    cells.append(create_markdown_cell([
        "## üîß Setup <a id=\"setup\"></a>\n",
        "\n",
        "Let's set up our test environment for model registry comparison."
    ]))
    
    # Dependencies and imports
    cells.append(create_code_cell([
        "# Cell 6: Check Dependencies and Imports\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check for SynaDB\n",
        "HAS_SYNADB = check_dependency('synadb', 'pip install synadb')\n",
        "\n",
        "# Check for MLflow\n",
        "HAS_MLFLOW = check_dependency('mlflow', 'pip install mlflow')\n",
        "\n",
        "# Check for DVC (optional - requires git repo)\n",
        "HAS_DVC = check_dependency('dvc', 'pip install dvc')\n",
        "\n",
        "# Apply consistent styling\n",
        "setup_style()"
    ]))
    
    # Configuration
    cells.append(create_code_cell([
        "# Cell 7: Configuration\n",
        "# Test configuration\n",
        "MODEL_SIZES_MB = [1, 10, 50]  # Model sizes to test\n",
        "NUM_VERSIONS = 10             # Versions per model\n",
        "SEED = 42                     # For reproducibility\n",
        "\n",
        "print('Test Configuration:')\n",
        "print(f'  Model sizes: {MODEL_SIZES_MB} MB')\n",
        "print(f'  Versions per model: {NUM_VERSIONS}')\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(SEED)"
    ]))
    
    # Create temp directory
    cells.append(create_code_cell([
        "# Cell 8: Create Temp Directory\n",
        "temp_dir = tempfile.mkdtemp(prefix='synadb_model_benchmark_')\n",
        "print(f'Using temp directory: {temp_dir}')\n",
        "\n",
        "# Paths for each system\n",
        "synadb_path = os.path.join(temp_dir, 'synadb_models.db')\n",
        "mlflow_path = os.path.join(temp_dir, 'mlruns')\n",
        "dvc_path = os.path.join(temp_dir, 'dvc_models')"
    ]))
    
    # Generate test data
    cells.append(create_code_cell([
        "# Cell 9: Generate Test Model Data\n",
        "# Generate model data of different sizes\n",
        "model_data = {}\n",
        "for size_mb in MODEL_SIZES_MB:\n",
        "    # Create random bytes to simulate model weights\n",
        "    model_data[size_mb] = np.random.bytes(size_mb * 1024 * 1024)\n",
        "    print(f'‚úì Generated {size_mb}MB model data')\n",
        "\n",
        "# Generate metadata for each version\n",
        "version_metadata = [\n",
        "    {\n",
        "        'accuracy': 0.85 + i * 0.01,\n",
        "        'loss': 0.5 - i * 0.03,\n",
        "        'epochs': 10 + i * 5,\n",
        "        'learning_rate': 0.001 * (0.9 ** i)\n",
        "    }\n",
        "    for i in range(NUM_VERSIONS)\n",
        "]\n",
        "print(f'‚úì Generated metadata for {NUM_VERSIONS} versions')"
    ]))
    
    return cells

def add_benchmark_cells(cells):
    """Add benchmark cells for model save/load."""
    # Benchmark header
    cells.append(create_markdown_cell([
        "## ‚ö° Benchmark: Model Save/Load <a id=\"benchmark-save-load\"></a>\n",
        "\n",
        "Let's measure how fast each system can save and load model versions."
    ]))
    
    # SynaDB save benchmark
    cells.append(create_code_cell([
        "# Cell 11: SynaDB Model Save Benchmark\n",
        "synadb_save_times = {size: [] for size in MODEL_SIZES_MB}\n",
        "synadb_registry = None\n",
        "\n",
        "if HAS_SYNADB:\n",
        "    from synadb import ModelRegistry\n",
        "    \n",
        "    print('Benchmarking SynaDB model save...')\n",
        "    synadb_registry = ModelRegistry(synadb_path)\n",
        "    \n",
        "    for size_mb in MODEL_SIZES_MB:\n",
        "        print(f'\\n  Testing {size_mb}MB model...')\n",
        "        for v in range(NUM_VERSIONS):\n",
        "            # Time model save\n",
        "            start = time.perf_counter()\n",
        "            version = synadb_registry.save_model(\n",
        "                f'model_{size_mb}mb',\n",
        "                model_data[size_mb],\n",
        "                {k: str(v) for k, v in version_metadata[v].items()}\n",
        "            )\n",
        "            elapsed = (time.perf_counter() - start) * 1000  # ms\n",
        "            synadb_save_times[size_mb].append(elapsed)\n",
        "        \n",
        "        throughput = size_mb * NUM_VERSIONS * 1000 / sum(synadb_save_times[size_mb])\n",
        "        print(f'    Mean: {np.mean(synadb_save_times[size_mb]):.2f}ms')\n",
        "        print(f'    Throughput: {throughput:.1f} MB/s')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available, skipping...')"
    ]))
    
    # MLflow save benchmark
    cells.append(create_code_cell([
        "# Cell 12: MLflow Model Save Benchmark\n",
        "mlflow_save_times = {size: [] for size in MODEL_SIZES_MB}\n",
        "\n",
        "if HAS_MLFLOW:\n",
        "    import mlflow\n",
        "    from mlflow.tracking import MlflowClient\n",
        "    \n",
        "    print('Benchmarking MLflow model save...')\n",
        "    mlflow.set_tracking_uri(f'file://{mlflow_path}')\n",
        "    client = MlflowClient()\n",
        "    \n",
        "    for size_mb in MODEL_SIZES_MB:\n",
        "        print(f'\\n  Testing {size_mb}MB model...')\n",
        "        model_name = f'model_{size_mb}mb'\n",
        "        \n",
        "        # Create temp file for model\n",
        "        model_file = os.path.join(temp_dir, f'temp_model_{size_mb}mb.bin')\n",
        "        with open(model_file, 'wb') as f:\n",
        "            f.write(model_data[size_mb])\n",
        "        \n",
        "        for v in range(NUM_VERSIONS):\n",
        "            # Time model save via MLflow\n",
        "            start = time.perf_counter()\n",
        "            with mlflow.start_run():\n",
        "                mlflow.log_artifact(model_file, 'model')\n",
        "                for k, val in version_metadata[v].items():\n",
        "                    mlflow.log_param(k, val)\n",
        "            elapsed = (time.perf_counter() - start) * 1000  # ms\n",
        "            mlflow_save_times[size_mb].append(elapsed)\n",
        "        \n",
        "        throughput = size_mb * NUM_VERSIONS * 1000 / sum(mlflow_save_times[size_mb])\n",
        "        print(f'    Mean: {np.mean(mlflow_save_times[size_mb]):.2f}ms')\n",
        "        print(f'    Throughput: {throughput:.1f} MB/s')\n",
        "else:\n",
        "    print('‚ö†Ô∏è MLflow not available, skipping...')"
    ]))
    
    # DVC save benchmark (simplified)
    cells.append(create_code_cell([
        "# Cell 13: DVC Model Save Benchmark (Simulated)\n",
        "dvc_save_times = {size: [] for size in MODEL_SIZES_MB}\n",
        "\n",
        "# Note: DVC requires a git repository, so we simulate the file operations\n",
        "print('Benchmarking DVC-style model save (file operations only)...')\n",
        "\n",
        "os.makedirs(dvc_path, exist_ok=True)\n",
        "\n",
        "for size_mb in MODEL_SIZES_MB:\n",
        "    print(f'\\n  Testing {size_mb}MB model...')\n",
        "    \n",
        "    for v in range(NUM_VERSIONS):\n",
        "        # Time file write + hash computation (DVC core operations)\n",
        "        start = time.perf_counter()\n",
        "        \n",
        "        # Write model file\n",
        "        model_file = os.path.join(dvc_path, f'model_{size_mb}mb_v{v}.bin')\n",
        "        with open(model_file, 'wb') as f:\n",
        "            f.write(model_data[size_mb])\n",
        "        \n",
        "        # Compute MD5 hash (DVC uses this for versioning)\n",
        "        md5_hash = hashlib.md5(model_data[size_mb]).hexdigest()\n",
        "        \n",
        "        elapsed = (time.perf_counter() - start) * 1000  # ms\n",
        "        dvc_save_times[size_mb].append(elapsed)\n",
        "    \n",
        "    throughput = size_mb * NUM_VERSIONS * 1000 / sum(dvc_save_times[size_mb])\n",
        "    print(f'    Mean: {np.mean(dvc_save_times[size_mb]):.2f}ms')\n",
        "    print(f'    Throughput: {throughput:.1f} MB/s')"
    ]))
    
    # Save results visualization
    cells.append(create_code_cell([
        "# Cell 14: Model Save Results Visualization\n",
        "# Compare save throughput for 10MB models\n",
        "save_throughput = {}\n",
        "test_size = 10  # Use 10MB for comparison\n",
        "\n",
        "if synadb_save_times[test_size]:\n",
        "    save_throughput['SynaDB'] = test_size * NUM_VERSIONS * 1000 / sum(synadb_save_times[test_size])\n",
        "\n",
        "if mlflow_save_times[test_size]:\n",
        "    save_throughput['MLflow'] = test_size * NUM_VERSIONS * 1000 / sum(mlflow_save_times[test_size])\n",
        "\n",
        "if dvc_save_times[test_size]:\n",
        "    save_throughput['DVC (file ops)'] = test_size * NUM_VERSIONS * 1000 / sum(dvc_save_times[test_size])\n",
        "\n",
        "if save_throughput:\n",
        "    fig = throughput_comparison(\n",
        "        save_throughput,\n",
        "        title=f'Model Save Throughput ({test_size}MB models)',\n",
        "        ylabel='MB/second'\n",
        "    )\n",
        "    plt.show()\n",
        "else:\n",
        "    print('No save results to display.')"
    ]))
    
    # Load benchmark
    cells.append(create_code_cell([
        "# Cell 15: SynaDB Model Load Benchmark\n",
        "synadb_load_times = {size: [] for size in MODEL_SIZES_MB}\n",
        "\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('Benchmarking SynaDB model load...')\n",
        "    \n",
        "    for size_mb in MODEL_SIZES_MB:\n",
        "        print(f'\\n  Testing {size_mb}MB model...')\n",
        "        for v in range(1, NUM_VERSIONS + 1):\n",
        "            # Time model load with checksum verification\n",
        "            start = time.perf_counter()\n",
        "            data, info = synadb_registry.load_model(f'model_{size_mb}mb', version=v)\n",
        "            elapsed = (time.perf_counter() - start) * 1000  # ms\n",
        "            synadb_load_times[size_mb].append(elapsed)\n",
        "        \n",
        "        throughput = size_mb * NUM_VERSIONS * 1000 / sum(synadb_load_times[size_mb])\n",
        "        print(f'    Mean: {np.mean(synadb_load_times[size_mb]):.2f}ms')\n",
        "        print(f'    Throughput: {throughput:.1f} MB/s')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available, skipping...')"
    ]))
    
    # Load results visualization
    cells.append(create_code_cell([
        "# Cell 16: Model Load Results Visualization\n",
        "load_throughput = {}\n",
        "test_size = 10  # Use 10MB for comparison\n",
        "\n",
        "if synadb_load_times[test_size]:\n",
        "    load_throughput['SynaDB'] = test_size * NUM_VERSIONS * 1000 / sum(synadb_load_times[test_size])\n",
        "\n",
        "# For MLflow and DVC, we'd need to implement load benchmarks\n",
        "# For now, show SynaDB results\n",
        "if load_throughput:\n",
        "    fig = throughput_comparison(\n",
        "        load_throughput,\n",
        "        title=f'Model Load Throughput ({test_size}MB models)',\n",
        "        ylabel='MB/second'\n",
        "    )\n",
        "    plt.show()\n",
        "else:\n",
        "    print('No load results to display.')"
    ]))
    
    return cells


def add_version_management_cells(cells):
    """Add version management demo cells."""
    cells.append(create_markdown_cell([
        "## üìã Demo: Version Management <a id=\"demo-version\"></a>\n",
        "\n",
        "Let's demonstrate how each system handles model versioning."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 18: SynaDB Version Management Demo\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('SynaDB Version Management')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    # List all versions of a model\n",
        "    versions = synadb_registry.list_versions('model_10mb')\n",
        "    print(f'\\nModel: model_10mb')\n",
        "    print(f'Total versions: {len(versions)}')\n",
        "    print('\\nVersion History:')\n",
        "    for v in versions[:5]:  # Show first 5\n",
        "        print(f'  v{v.version}: {v.stage} - checksum: {v.checksum[:16]}...')\n",
        "    \n",
        "    # Get specific version\n",
        "    print('\\n\\nLoading specific version (v3)...')\n",
        "    data, info = synadb_registry.load_model('model_10mb', version=3)\n",
        "    print(f'  Loaded {len(data) / (1024*1024):.1f}MB')\n",
        "    print(f'  Stage: {info.stage}')\n",
        "    print(f'  Checksum verified: ‚úì')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 19: Version Management Comparison Table\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "comparison = '''\n",
        "### Version Management Comparison\n",
        "\n",
        "| Feature | SynaDB | MLflow | DVC |\n",
        "|---------|--------|--------|-----|\n",
        "| **Auto-versioning** | ‚úÖ Automatic | ‚úÖ Automatic | ‚ö†Ô∏è Manual commits |\n",
        "| **Version numbering** | ‚úÖ Sequential | ‚úÖ Sequential | ‚ö†Ô∏è Git hashes |\n",
        "| **Metadata per version** | ‚úÖ Built-in | ‚úÖ Built-in | ‚ö†Ô∏è Separate files |\n",
        "| **Query versions** | ‚úÖ Fast (indexed) | ‚úÖ API calls | ‚ö†Ô∏è Git log parsing |\n",
        "| **Storage efficiency** | ‚úÖ Single file | ‚ö†Ô∏è Directory per run | ‚ö†Ô∏è Cache directory |\n",
        "| **Offline support** | ‚úÖ Full | ‚ö†Ô∏è Local mode | ‚úÖ Full |\n",
        "'''\n",
        "display(Markdown(comparison))"
    ]))
    
    return cells

def add_stage_promotion_cells(cells):
    """Add stage promotion demo cells."""
    cells.append(create_markdown_cell([
        "## üöÄ Demo: Stage Promotion <a id=\"demo-stage\"></a>\n",
        "\n",
        "Model lifecycle management: Development ‚Üí Staging ‚Üí Production"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 21: SynaDB Stage Promotion Demo\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('SynaDB Stage Promotion Workflow')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    model_name = 'model_10mb'\n",
        "    \n",
        "    # Check current stages\n",
        "    print('\\nCurrent version stages:')\n",
        "    versions = synadb_registry.list_versions(model_name)\n",
        "    for v in versions[:3]:\n",
        "        print(f'  v{v.version}: {v.stage}')\n",
        "    \n",
        "    # Promote version 5 to Staging\n",
        "    print('\\n\\nPromoting v5 to Staging...')\n",
        "    synadb_registry.set_stage(model_name, 5, 'Staging')\n",
        "    print('  ‚úì v5 is now in Staging')\n",
        "    \n",
        "    # Promote version 8 to Production\n",
        "    print('\\nPromoting v8 to Production...')\n",
        "    synadb_registry.set_stage(model_name, 8, 'Production')\n",
        "    print('  ‚úì v8 is now in Production')\n",
        "    \n",
        "    # Get production model\n",
        "    print('\\n\\nGetting production model...')\n",
        "    prod = synadb_registry.get_production(model_name)\n",
        "    if prod:\n",
        "        print(f'  Production version: v{prod.version}')\n",
        "        print(f'  Checksum: {prod.checksum[:16]}...')\n",
        "    \n",
        "    # Show updated stages\n",
        "    print('\\n\\nUpdated version stages:')\n",
        "    versions = synadb_registry.list_versions(model_name)\n",
        "    for v in versions:\n",
        "        if v.stage != 'Development':\n",
        "            print(f'  v{v.version}: {v.stage}')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 22: Stage Promotion Comparison\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "stage_comparison = '''\n",
        "### Stage Promotion Comparison\n",
        "\n",
        "| Feature | SynaDB | MLflow | DVC |\n",
        "|---------|--------|--------|-----|\n",
        "| **Built-in stages** | ‚úÖ Dev/Staging/Prod/Archived | ‚úÖ Similar | ‚ùå None |\n",
        "| **Promotion API** | ‚úÖ `set_stage()` | ‚úÖ `transition_model_version_stage()` | ‚ùå Manual |\n",
        "| **Get production** | ‚úÖ `get_production()` | ‚úÖ Filter by stage | ‚ùå Manual |\n",
        "| **Stage history** | ‚úÖ Tracked | ‚úÖ Tracked | ‚ùå Git history |\n",
        "| **Approval workflow** | ‚ö†Ô∏è Manual | ‚úÖ Built-in | ‚ùå None |\n",
        "\n",
        "**SynaDB Stages:**\n",
        "- `Development` - Initial stage for new models\n",
        "- `Staging` - Testing/validation stage\n",
        "- `Production` - Live deployment stage\n",
        "- `Archived` - Deprecated models\n",
        "'''\n",
        "display(Markdown(stage_comparison))"
    ]))
    
    return cells

def add_rollback_cells(cells):
    """Add rollback demo cells."""
    cells.append(create_markdown_cell([
        "## ‚è™ Demo: Rollback <a id=\"demo-rollback\"></a>\n",
        "\n",
        "Demonstrating how to rollback to a previous model version."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 24: SynaDB Rollback Demo\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('SynaDB Rollback Workflow')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    model_name = 'model_10mb'\n",
        "    \n",
        "    # Current production\n",
        "    print('\\nCurrent production model:')\n",
        "    prod = synadb_registry.get_production(model_name)\n",
        "    if prod:\n",
        "        print(f'  Version: v{prod.version}')\n",
        "    \n",
        "    # Simulate rollback: demote current, promote previous\n",
        "    print('\\n\\nRolling back to v5...')\n",
        "    \n",
        "    # Archive current production\n",
        "    if prod:\n",
        "        synadb_registry.set_stage(model_name, prod.version, 'Archived')\n",
        "        print(f'  ‚úì v{prod.version} archived')\n",
        "    \n",
        "    # Promote v5 to production\n",
        "    synadb_registry.set_stage(model_name, 5, 'Production')\n",
        "    print('  ‚úì v5 promoted to Production')\n",
        "    \n",
        "    # Verify rollback\n",
        "    print('\\n\\nVerifying rollback...')\n",
        "    new_prod = synadb_registry.get_production(model_name)\n",
        "    if new_prod:\n",
        "        print(f'  New production version: v{new_prod.version}')\n",
        "        \n",
        "        # Load and verify integrity\n",
        "        data, info = synadb_registry.load_model(model_name, version=new_prod.version)\n",
        "        print(f'  Integrity verified: ‚úì (SHA-256 checksum)')\n",
        "        print(f'  Model size: {len(data) / (1024*1024):.1f}MB')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 25: Rollback Comparison\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "rollback_comparison = '''\n",
        "### Rollback Comparison\n",
        "\n",
        "| Feature | SynaDB | MLflow | DVC |\n",
        "|---------|--------|--------|-----|\n",
        "| **Rollback method** | Stage change | Stage change | `dvc checkout` |\n",
        "| **Speed** | ‚úÖ Instant | ‚úÖ Instant | ‚ö†Ô∏è File copy |\n",
        "| **Integrity check** | ‚úÖ SHA-256 | ‚ö†Ô∏è Optional | ‚úÖ MD5 |\n",
        "| **Audit trail** | ‚úÖ Tracked | ‚úÖ Tracked | ‚úÖ Git history |\n",
        "| **Atomic operation** | ‚úÖ Yes | ‚úÖ Yes | ‚ö†Ô∏è Multi-step |\n",
        "'''\n",
        "display(Markdown(rollback_comparison))"
    ]))
    
    return cells


def add_integrity_cells(cells):
    """Add integrity guarantee cells."""
    cells.append(create_markdown_cell([
        "## üîí Integrity Guarantees <a id=\"integrity\"></a>\n",
        "\n",
        "Comparing data integrity features across systems."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 27: SynaDB Integrity Demo\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('SynaDB Integrity Guarantees')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    model_name = 'model_10mb'\n",
        "    \n",
        "    # Load model with checksum verification\n",
        "    print('\\nLoading model with integrity verification...')\n",
        "    data, info = synadb_registry.load_model(model_name, version=1)\n",
        "    \n",
        "    print(f'\\n  Model: {model_name}')\n",
        "    print(f'  Version: v{info.version}')\n",
        "    print(f'  Size: {len(data) / (1024*1024):.1f}MB')\n",
        "    print(f'  Checksum (SHA-256): {info.checksum}')\n",
        "    print(f'  Verification: ‚úì Automatic on load')\n",
        "    \n",
        "    # Verify checksum manually\n",
        "    print('\\n\\nManual checksum verification...')\n",
        "    computed_hash = hashlib.sha256(data).hexdigest()\n",
        "    matches = computed_hash == info.checksum\n",
        "    print(f'  Computed: {computed_hash[:32]}...')\n",
        "    print(f'  Stored:   {info.checksum[:32]}...')\n",
        "    print(f'  Match: {\"‚úì\" if matches else \"‚úó\"}')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 28: Integrity Comparison Table\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "integrity_comparison = '''\n",
        "### Integrity Guarantee Comparison\n",
        "\n",
        "| Feature | SynaDB | MLflow | DVC |\n",
        "|---------|--------|--------|-----|\n",
        "| **Checksum algorithm** | SHA-256 | None (optional) | MD5 |\n",
        "| **Auto-verification** | ‚úÖ On every load | ‚ùå Manual | ‚úÖ On checkout |\n",
        "| **Corruption detection** | ‚úÖ Immediate | ‚ùå None | ‚úÖ On access |\n",
        "| **Tamper detection** | ‚úÖ Cryptographic | ‚ùå None | ‚ö†Ô∏è MD5 (weak) |\n",
        "| **Checksum storage** | ‚úÖ With model | ‚ùå Separate | ‚úÖ .dvc files |\n",
        "\n",
        "**Why SHA-256?**\n",
        "- Cryptographically secure (unlike MD5)\n",
        "- Detects both accidental corruption and tampering\n",
        "- Industry standard for data integrity\n",
        "- Fast enough for large models\n",
        "'''\n",
        "display(Markdown(integrity_comparison))"
    ]))
    
    return cells

def add_results_cells(cells):
    """Add results summary cells."""
    cells.append(create_markdown_cell([
        "## üìä Results Summary <a id=\"results\"></a>\n",
        "\n",
        "Let's summarize all benchmark results and comparisons."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 30: Results Summary Table\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Build summary\n",
        "summary_lines = ['### Performance Summary\\n']\n",
        "summary_lines.append('| Metric | SynaDB | MLflow | DVC |')\n",
        "summary_lines.append('|--------|--------|--------|-----|')\n",
        "\n",
        "# Save throughput (10MB)\n",
        "test_size = 10\n",
        "if synadb_save_times.get(test_size):\n",
        "    synadb_tp = test_size * NUM_VERSIONS * 1000 / sum(synadb_save_times[test_size])\n",
        "else:\n",
        "    synadb_tp = 'N/A'\n",
        "\n",
        "if mlflow_save_times.get(test_size):\n",
        "    mlflow_tp = test_size * NUM_VERSIONS * 1000 / sum(mlflow_save_times[test_size])\n",
        "else:\n",
        "    mlflow_tp = 'N/A'\n",
        "\n",
        "if dvc_save_times.get(test_size):\n",
        "    dvc_tp = test_size * NUM_VERSIONS * 1000 / sum(dvc_save_times[test_size])\n",
        "else:\n",
        "    dvc_tp = 'N/A'\n",
        "\n",
        "synadb_str = f'{synadb_tp:.1f} MB/s' if isinstance(synadb_tp, float) else synadb_tp\n",
        "mlflow_str = f'{mlflow_tp:.1f} MB/s' if isinstance(mlflow_tp, float) else mlflow_tp\n",
        "dvc_str = f'{dvc_tp:.1f} MB/s' if isinstance(dvc_tp, float) else dvc_tp\n",
        "\n",
        "summary_lines.append(f'| Save throughput (10MB) | **{synadb_str}** | {mlflow_str} | {dvc_str} |')\n",
        "\n",
        "# Add feature comparison\n",
        "summary_lines.append('| Checksum verification | ‚úÖ SHA-256 | ‚ùå None | ‚úÖ MD5 |')\n",
        "summary_lines.append('| Stage management | ‚úÖ Built-in | ‚úÖ Built-in | ‚ùå None |')\n",
        "summary_lines.append('| Single file storage | ‚úÖ Yes | ‚ùå Directory | ‚ùå Cache |')\n",
        "summary_lines.append('| Offline support | ‚úÖ Full | ‚ö†Ô∏è Local mode | ‚úÖ Full |')\n",
        "\n",
        "display(Markdown('\\n'.join(summary_lines)))"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 31: Feature Comparison Chart\n",
        "# Create a feature comparison visualization\n",
        "features = ['Embedded', 'Checksums', 'Stages', 'Offline', 'Single File']\n",
        "synadb_scores = [1, 1, 1, 1, 1]  # All features\n",
        "mlflow_scores = [0, 0, 1, 0.5, 0]  # Server-based, no checksums, has stages\n",
        "dvc_scores = [1, 0.5, 0, 1, 0]  # Embedded, MD5, no stages\n",
        "\n",
        "x = np.arange(len(features))\n",
        "width = 0.25\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(x - width, synadb_scores, width, label='SynaDB', color=COLORS['synadb'])\n",
        "bars2 = ax.bar(x, mlflow_scores, width, label='MLflow', color=COLORS['competitor'])\n",
        "bars3 = ax.bar(x + width, dvc_scores, width, label='DVC', color=COLORS['competitor_alt'])\n",
        "\n",
        "ax.set_ylabel('Feature Support')\n",
        "ax.set_title('Model Registry Feature Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(features)\n",
        "ax.set_ylim(0, 1.2)\n",
        "ax.legend()\n",
        "ax.set_yticks([0, 0.5, 1])\n",
        "ax.set_yticklabels(['None', 'Partial', 'Full'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]))
    
    return cells

def add_conclusion_cells(cells):
    """Add conclusion cells."""
    cells.append(create_markdown_cell([
        "## üéØ Conclusions <a id=\"conclusions\"></a>"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 33: Conclusions\n",
        "conclusion_box(\n",
        "    title='Key Takeaways',\n",
        "    points=[\n",
        "        'SynaDB provides embedded model registry with SHA-256 integrity verification',\n",
        "        'Single-file storage simplifies deployment and backup',\n",
        "        'Built-in stage management (Dev ‚Üí Staging ‚Üí Production ‚Üí Archived)',\n",
        "        'Offline-first design - no server or network required',\n",
        "        'MLflow offers richer UI but requires server infrastructure',\n",
        "        'DVC integrates with Git but lacks built-in stage management'\n",
        "    ],\n",
        "    summary='SynaDB is ideal for embedded ML applications needing simple, reliable model versioning.'\n",
        ")"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 34: Cleanup\n",
        "# Clean up temp directory\n",
        "import shutil\n",
        "try:\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(f'‚úì Cleaned up temp directory: {temp_dir}')\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è Could not clean up: {e}')"
    ]))
    
    cells.append(create_markdown_cell([
        "---\n",
        "\n",
        "**Next Steps:**\n",
        "- Try the [Hugging Face Hub comparison](11_huggingface_hub.ipynb) for transformer model storage\n",
        "- Explore [LLM Framework integrations](../llm_frameworks/) for RAG applications\n",
        "- Check out [End-to-End Pipeline](../specialized/18_end_to_end_pipeline.ipynb) for complete ML workflows"
    ]))
    
    return cells

def build_complete_notebook():
    """Build the complete 10_mlflow_dvc.ipynb notebook."""
    cells = generate_10_mlflow_dvc()
    cells = add_setup_cells(cells)
    cells = add_benchmark_cells(cells)
    cells = add_version_management_cells(cells)
    cells = add_stage_promotion_cells(cells)
    cells = add_rollback_cells(cells)
    cells = add_integrity_cells(cells)
    cells = add_results_cells(cells)
    cells = add_conclusion_cells(cells)
    
    notebook = {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.9.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    with open('10_mlflow_dvc.ipynb', 'w') as f:
        json.dump(notebook, f, indent=1)
    
    print(f"Generated 10_mlflow_dvc.ipynb with {len(cells)} cells")

if __name__ == "__main__":
    build_complete_notebook()


# ============================================================================
# 11_huggingface_hub.ipynb Generator
# ============================================================================

def generate_11_huggingface_hub():
    """Generate the Hugging Face Hub comparison notebook."""
    cells = []
    
    # Cell 1: Header and Setup
    cells.append(create_code_cell([
        "# Cell 1: Header and Setup\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from utils.notebook_utils import display_header, display_toc, check_dependency, conclusion_box\n",
        "from utils.system_info import display_system_info\n",
        "from utils.benchmark import Benchmark, BenchmarkResult, ComparisonTable\n",
        "from utils.charts import setup_style, bar_comparison, throughput_comparison, COLORS\n",
        "\n",
        "display_header('Model Registry Comparison', 'SynaDB vs Hugging Face Hub')"
    ]))
    
    # Cell 2: Table of Contents
    cells.append(create_code_cell([
        "# Cell 2: Table of Contents\n",
        "sections = [\n",
        "    ('Introduction', 'introduction'),\n",
        "    ('Setup', 'setup'),\n",
        "    ('Transformer Model Storage', 'transformer-storage'),\n",
        "    ('Load Time Comparison', 'load-time'),\n",
        "    ('Version Management', 'version-management'),\n",
        "    ('Fine-tuned Models', 'fine-tuned'),\n",
        "    ('Offline Usage', 'offline'),\n",
        "    ('Results Summary', 'results'),\n",
        "    ('Conclusions', 'conclusions'),\n",
        "]\n",
        "display_toc(sections)"
    ]))
    
    # Cell 3: Introduction
    cells.append(create_markdown_cell([
        "## üìå Introduction <a id=\"introduction\"></a>\n",
        "\n",
        "This notebook compares **SynaDB's ModelRegistry** against **Hugging Face Hub** for transformer model storage.\n",
        "\n",
        "| System | Type | Key Features |\n",
        "|--------|------|-------------|\n",
        "| **SynaDB** | Local/Embedded | Single-file, offline-first, SHA-256 checksums |\n",
        "| **Hugging Face Hub** | Cloud | Largest model repository, community sharing, model cards |\n",
        "\n",
        "### What We'll Compare\n",
        "\n",
        "- **Transformer model storage** - Saving and loading model weights\n",
        "- **Load time** - Local SynaDB vs HF Hub download\n",
        "- **Version management** - Local versioning vs Hub revisions\n",
        "- **Fine-tuned models** - Storing custom model weights\n",
        "- **Offline usage** - Air-gapped environment support\n",
        "\n",
        "### Use Cases\n",
        "\n",
        "- **SynaDB**: Local development, edge deployment, air-gapped environments\n",
        "- **HF Hub**: Model sharing, community collaboration, cloud deployment"
    ]))
    
    # Cell 4: System Info
    cells.append(create_code_cell([
        "# Cell 4: System Info\n",
        "display_system_info()"
    ]))
    
    return cells

def add_hf_setup_cells(cells):
    """Add setup cells for HF Hub notebook."""
    cells.append(create_markdown_cell([
        "## üîß Setup <a id=\"setup\"></a>\n",
        "\n",
        "Let's set up our test environment for model storage comparison."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 6: Check Dependencies and Imports\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check for SynaDB\n",
        "HAS_SYNADB = check_dependency('synadb', 'pip install synadb')\n",
        "\n",
        "# Check for Hugging Face Hub\n",
        "HAS_HF_HUB = check_dependency('huggingface_hub', 'pip install huggingface_hub')\n",
        "\n",
        "# Check for transformers (optional, for real model tests)\n",
        "HAS_TRANSFORMERS = check_dependency('transformers', 'pip install transformers')\n",
        "\n",
        "# Apply consistent styling\n",
        "setup_style()"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 7: Configuration\n",
        "# Test configuration\n",
        "SEED = 42\n",
        "NUM_VERSIONS = 5  # Number of model versions to test\n",
        "\n",
        "# Simulated model sizes (in MB)\n",
        "# Real transformer models: BERT-base ~440MB, GPT-2 ~500MB, etc.\n",
        "SIMULATED_MODEL_SIZE_MB = 50  # Smaller for faster testing\n",
        "\n",
        "print('Test Configuration:')\n",
        "print(f'  Simulated model size: {SIMULATED_MODEL_SIZE_MB}MB')\n",
        "print(f'  Number of versions: {NUM_VERSIONS}')\n",
        "\n",
        "np.random.seed(SEED)"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 8: Create Temp Directory\n",
        "temp_dir = tempfile.mkdtemp(prefix='synadb_hf_benchmark_')\n",
        "print(f'Using temp directory: {temp_dir}')\n",
        "\n",
        "# Paths\n",
        "synadb_path = os.path.join(temp_dir, 'synadb_models.db')\n",
        "hf_cache_path = os.path.join(temp_dir, 'hf_cache')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 9: Generate Simulated Model Data\n",
        "# Generate simulated transformer model weights\n",
        "# In practice, these would be actual PyTorch state_dict or safetensors\n",
        "\n",
        "def generate_model_weights(size_mb, version):\n",
        "    \"\"\"Generate simulated model weights with version-specific variations.\"\"\"\n",
        "    np.random.seed(SEED + version)\n",
        "    return np.random.bytes(size_mb * 1024 * 1024)\n",
        "\n",
        "# Generate multiple versions\n",
        "model_versions = {}\n",
        "for v in range(NUM_VERSIONS):\n",
        "    model_versions[v] = generate_model_weights(SIMULATED_MODEL_SIZE_MB, v)\n",
        "    print(f'‚úì Generated model version {v+1} ({SIMULATED_MODEL_SIZE_MB}MB)')\n",
        "\n",
        "# Model metadata (simulating HF model card info)\n",
        "model_metadata = {\n",
        "    'model_type': 'bert',\n",
        "    'hidden_size': 768,\n",
        "    'num_attention_heads': 12,\n",
        "    'num_hidden_layers': 12,\n",
        "    'vocab_size': 30522,\n",
        "}"
    ]))
    
    return cells

def add_transformer_storage_cells(cells):
    """Add transformer model storage cells."""
    cells.append(create_markdown_cell([
        "## ü§ñ Transformer Model Storage <a id=\"transformer-storage\"></a>\n",
        "\n",
        "Comparing how each system stores transformer model weights."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 11: SynaDB Transformer Storage\n",
        "synadb_save_times = []\n",
        "synadb_registry = None\n",
        "\n",
        "if HAS_SYNADB:\n",
        "    from synadb import ModelRegistry\n",
        "    \n",
        "    print('Storing transformer models in SynaDB...')\n",
        "    synadb_registry = ModelRegistry(synadb_path)\n",
        "    \n",
        "    for v in range(NUM_VERSIONS):\n",
        "        # Time model save\n",
        "        start = time.perf_counter()\n",
        "        version_info = synadb_registry.save_model(\n",
        "            'bert-base-custom',\n",
        "            model_versions[v],\n",
        "            {**model_metadata, 'fine_tuned_epoch': str(v * 10)}\n",
        "        )\n",
        "        elapsed = (time.perf_counter() - start) * 1000\n",
        "        synadb_save_times.append(elapsed)\n",
        "        print(f'  v{v+1}: {elapsed:.2f}ms')\n",
        "    \n",
        "    throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_save_times)\n",
        "    print(f'\\n‚úì Saved {NUM_VERSIONS} versions')\n",
        "    print(f'  Mean: {np.mean(synadb_save_times):.2f}ms')\n",
        "    print(f'  Throughput: {throughput:.1f} MB/s')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 12: HF Hub Storage Pattern (Simulated)\n",
        "hf_save_times = []\n",
        "\n",
        "# Note: Actual HF Hub upload requires authentication and network\n",
        "# We simulate the local file operations that HF Hub performs\n",
        "\n",
        "print('Simulating Hugging Face Hub storage pattern...')\n",
        "os.makedirs(hf_cache_path, exist_ok=True)\n",
        "\n",
        "for v in range(NUM_VERSIONS):\n",
        "    # Simulate HF Hub's local caching behavior\n",
        "    start = time.perf_counter()\n",
        "    \n",
        "    # HF Hub stores models in a specific directory structure\n",
        "    model_dir = os.path.join(hf_cache_path, f'models--bert-base-custom', f'snapshots', f'v{v}')\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    \n",
        "    # Write model weights (simulating safetensors or pytorch_model.bin)\n",
        "    model_file = os.path.join(model_dir, 'pytorch_model.bin')\n",
        "    with open(model_file, 'wb') as f:\n",
        "        f.write(model_versions[v])\n",
        "    \n",
        "    # Write config (simulating config.json)\n",
        "    import json\n",
        "    config_file = os.path.join(model_dir, 'config.json')\n",
        "    with open(config_file, 'w') as f:\n",
        "        json.dump(model_metadata, f)\n",
        "    \n",
        "    elapsed = (time.perf_counter() - start) * 1000\n",
        "    hf_save_times.append(elapsed)\n",
        "    print(f'  v{v+1}: {elapsed:.2f}ms')\n",
        "\n",
        "throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(hf_save_times)\n",
        "print(f'\\n‚úì Saved {NUM_VERSIONS} versions (local cache simulation)')\n",
        "print(f'  Mean: {np.mean(hf_save_times):.2f}ms')\n",
        "print(f'  Throughput: {throughput:.1f} MB/s')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 13: Storage Comparison Visualization\n",
        "save_throughput = {}\n",
        "\n",
        "if synadb_save_times:\n",
        "    save_throughput['SynaDB'] = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_save_times)\n",
        "\n",
        "if hf_save_times:\n",
        "    save_throughput['HF Hub (local)'] = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(hf_save_times)\n",
        "\n",
        "if save_throughput:\n",
        "    fig = throughput_comparison(\n",
        "        save_throughput,\n",
        "        title=f'Model Storage Throughput ({SIMULATED_MODEL_SIZE_MB}MB models)',\n",
        "        ylabel='MB/second'\n",
        "    )\n",
        "    plt.show()"
    ]))
    
    return cells

def add_load_time_cells(cells):
    """Add load time comparison cells."""
    cells.append(create_markdown_cell([
        "## ‚è±Ô∏è Load Time Comparison <a id=\"load-time\"></a>\n",
        "\n",
        "Comparing local load times vs network download times."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 15: SynaDB Load Time\n",
        "synadb_load_times = []\n",
        "\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('Benchmarking SynaDB model load...')\n",
        "    \n",
        "    for v in range(1, NUM_VERSIONS + 1):\n",
        "        # Time model load with checksum verification\n",
        "        start = time.perf_counter()\n",
        "        data, info = synadb_registry.load_model('bert-base-custom', version=v)\n",
        "        elapsed = (time.perf_counter() - start) * 1000\n",
        "        synadb_load_times.append(elapsed)\n",
        "        print(f'  v{v}: {elapsed:.2f}ms (verified)')\n",
        "    \n",
        "    throughput = SIMULATED_MODEL_SIZE_MB * NUM_VERSIONS * 1000 / sum(synadb_load_times)\n",
        "    print(f'\\n‚úì Loaded {NUM_VERSIONS} versions')\n",
        "    print(f'  Mean: {np.mean(synadb_load_times):.2f}ms')\n",
        "    print(f'  Throughput: {throughput:.1f} MB/s')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 16: HF Hub Load Time (Local Cache)\n",
        "hf_load_times = []\n",
        "\n",
        "print('Benchmarking HF Hub local cache load...')\n",
        "\n",
        "for v in range(NUM_VERSIONS):\n",
        "    model_file = os.path.join(hf_cache_path, f'models--bert-base-custom', f'snapshots', f'v{v}', 'pytorch_model.bin')\n",
        "    \n",
        "    if os.path.exists(model_file):\n",
        "        start = time.perf_counter()\n",
        "        with open(model_file, 'rb') as f:\n",
        "            data = f.read()\n",
        "        elapsed = (time.perf_counter() - start) * 1000\n",
        "        hf_load_times.append(elapsed)\n",
        "        print(f'  v{v+1}: {elapsed:.2f}ms')\n",
        "\n",
        "if hf_load_times:\n",
        "    throughput = SIMULATED_MODEL_SIZE_MB * len(hf_load_times) * 1000 / sum(hf_load_times)\n",
        "    print(f'\\n‚úì Loaded {len(hf_load_times)} versions from cache')\n",
        "    print(f'  Mean: {np.mean(hf_load_times):.2f}ms')\n",
        "    print(f'  Throughput: {throughput:.1f} MB/s')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 17: Load Time Comparison\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Estimated HF Hub download times (based on typical network speeds)\n",
        "# Assuming 50Mbps connection for a 50MB model\n",
        "estimated_download_time_ms = SIMULATED_MODEL_SIZE_MB * 8 / 50 * 1000  # ~8 seconds\n",
        "\n",
        "load_comparison = f'''\n",
        "### Load Time Comparison\n",
        "\n",
        "| Scenario | SynaDB | HF Hub (cached) | HF Hub (download) |\n",
        "|----------|--------|-----------------|-------------------|\n",
        "| **First load** | {np.mean(synadb_load_times) if synadb_load_times else 'N/A':.0f}ms | {np.mean(hf_load_times) if hf_load_times else 'N/A':.0f}ms | ~{estimated_download_time_ms:.0f}ms* |\n",
        "| **Cached load** | {np.mean(synadb_load_times) if synadb_load_times else 'N/A':.0f}ms | {np.mean(hf_load_times) if hf_load_times else 'N/A':.0f}ms | {np.mean(hf_load_times) if hf_load_times else 'N/A':.0f}ms |\n",
        "| **Checksum verification** | ‚úÖ Automatic | ‚ùå None | ‚ùå None |\n",
        "\n",
        "*Estimated for {SIMULATED_MODEL_SIZE_MB}MB model on 50Mbps connection\n",
        "\n",
        "**Key Insight:** SynaDB provides consistent, fast load times with built-in integrity verification.\n",
        "HF Hub requires network access for first load, then caches locally.\n",
        "'''\n",
        "display(Markdown(load_comparison))"
    ]))
    
    return cells


def add_hf_version_management_cells(cells):
    """Add version management cells for HF notebook."""
    cells.append(create_markdown_cell([
        "## üìã Version Management <a id=\"version-management\"></a>\n",
        "\n",
        "Comparing version management approaches."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 19: SynaDB Version Management\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('SynaDB Version Management')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    # List versions\n",
        "    versions = synadb_registry.list_versions('bert-base-custom')\n",
        "    print(f'\\nModel: bert-base-custom')\n",
        "    print(f'Total versions: {len(versions)}')\n",
        "    \n",
        "    print('\\nVersion History:')\n",
        "    for v in versions:\n",
        "        print(f'  v{v.version}: {v.stage}')\n",
        "        print(f'    Checksum: {v.checksum[:24]}...')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 20: Version Management Comparison\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "version_comparison = '''\n",
        "### Version Management Comparison\n",
        "\n",
        "| Feature | SynaDB | Hugging Face Hub |\n",
        "|---------|--------|------------------|\n",
        "| **Version identifier** | Sequential numbers | Git commit hashes |\n",
        "| **Version listing** | `list_versions()` | `list_repo_refs()` |\n",
        "| **Load specific version** | `load_model(name, version=N)` | `revision=\"commit_hash\"` |\n",
        "| **Metadata per version** | ‚úÖ Built-in | ‚úÖ Model cards |\n",
        "| **Offline versioning** | ‚úÖ Full support | ‚ùå Requires network |\n",
        "| **Private versions** | ‚úÖ Local only | ‚úÖ Private repos |\n",
        "\n",
        "**SynaDB Approach:**\n",
        "```python\n",
        "# Simple sequential versioning\n",
        "registry.save_model(\"my-model\", weights, metadata)  # Auto v1, v2, v3...\n",
        "data, info = registry.load_model(\"my-model\", version=2)\n",
        "```\n",
        "\n",
        "**HF Hub Approach:**\n",
        "```python\n",
        "# Git-based versioning\n",
        "model = AutoModel.from_pretrained(\"user/model\", revision=\"abc123\")\n",
        "```\n",
        "'''\n",
        "display(Markdown(version_comparison))"
    ]))
    
    return cells

def add_fine_tuned_cells(cells):
    """Add fine-tuned model cells."""
    cells.append(create_markdown_cell([
        "## üéØ Fine-tuned Models <a id=\"fine-tuned\"></a>\n",
        "\n",
        "Demonstrating storage of fine-tuned model weights."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 22: Fine-tuned Model Storage Demo\n",
        "if HAS_SYNADB and synadb_registry:\n",
        "    print('Storing Fine-tuned Models in SynaDB')\n",
        "    print('=' * 50)\n",
        "    \n",
        "    # Simulate fine-tuning iterations\n",
        "    fine_tune_metadata = [\n",
        "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.92', 'epochs': '3'},\n",
        "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.94', 'epochs': '5'},\n",
        "        {'task': 'sentiment', 'dataset': 'imdb', 'accuracy': '0.95', 'epochs': '10'},\n",
        "    ]\n",
        "    \n",
        "    print('\\nSaving fine-tuned checkpoints...')\n",
        "    for i, meta in enumerate(fine_tune_metadata):\n",
        "        # Generate slightly different weights for each checkpoint\n",
        "        weights = generate_model_weights(10, 100 + i)  # 10MB for faster demo\n",
        "        \n",
        "        version = synadb_registry.save_model(\n",
        "            'bert-sentiment-finetuned',\n",
        "            weights,\n",
        "            meta\n",
        "        )\n",
        "        print(f'  Checkpoint {i+1}: accuracy={meta[\"accuracy\"]}, epochs={meta[\"epochs\"]}')\n",
        "    \n",
        "    # Promote best model to production\n",
        "    print('\\n\\nPromoting best model (v3) to Production...')\n",
        "    synadb_registry.set_stage('bert-sentiment-finetuned', 3, 'Production')\n",
        "    \n",
        "    # Get production model\n",
        "    prod = synadb_registry.get_production('bert-sentiment-finetuned')\n",
        "    if prod:\n",
        "        print(f'  ‚úì Production model: v{prod.version}')\n",
        "        print(f'  ‚úì Checksum: {prod.checksum[:24]}...')\n",
        "else:\n",
        "    print('‚ö†Ô∏è SynaDB not available')"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 23: Fine-tuned Model Comparison\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "finetune_comparison = '''\n",
        "### Fine-tuned Model Storage Comparison\n",
        "\n",
        "| Feature | SynaDB | Hugging Face Hub |\n",
        "|---------|--------|------------------|\n",
        "| **Store checkpoints** | ‚úÖ `save_model()` | ‚úÖ `push_to_hub()` |\n",
        "| **Track training metadata** | ‚úÖ Built-in | ‚úÖ Model cards |\n",
        "| **Compare versions** | ‚úÖ `list_versions()` | ‚úÖ Hub UI |\n",
        "| **Promote to production** | ‚úÖ `set_stage()` | ‚ö†Ô∏è Manual tags |\n",
        "| **Offline fine-tuning** | ‚úÖ Full support | ‚ùå Requires network to push |\n",
        "| **Private storage** | ‚úÖ Local only | ‚úÖ Private repos (paid) |\n",
        "\n",
        "**Best Practice:** Use SynaDB for local development and checkpointing,\n",
        "then push final models to HF Hub for sharing.\n",
        "'''\n",
        "display(Markdown(finetune_comparison))"
    ]))
    
    return cells

def add_offline_cells(cells):
    """Add offline usage cells."""
    cells.append(create_markdown_cell([
        "## üîå Offline Usage <a id=\"offline\"></a>\n",
        "\n",
        "Demonstrating SynaDB's advantage in air-gapped environments."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 25: Offline Usage Demonstration\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "offline_demo = '''\n",
        "### Offline Usage Comparison\n",
        "\n",
        "| Scenario | SynaDB | Hugging Face Hub |\n",
        "|----------|--------|------------------|\n",
        "| **Air-gapped environment** | ‚úÖ Full functionality | ‚ùå No access |\n",
        "| **Edge deployment** | ‚úÖ Single file | ‚ö†Ô∏è Pre-download required |\n",
        "| **No internet** | ‚úÖ Works perfectly | ‚ùå Cache only |\n",
        "| **Secure environments** | ‚úÖ No network calls | ‚ö†Ô∏è Firewall issues |\n",
        "| **Reproducibility** | ‚úÖ Checksums | ‚ö†Ô∏è Network-dependent |\n",
        "\n",
        "### SynaDB Offline Workflow\n",
        "\n",
        "```python\n",
        "# Works anywhere - no network required\n",
        "from synadb import ModelRegistry\n",
        "\n",
        "# Single file contains all models and versions\n",
        "registry = ModelRegistry(\"models.db\")\n",
        "\n",
        "# Save model\n",
        "registry.save_model(\"my-model\", weights, metadata)\n",
        "\n",
        "# Load with integrity verification\n",
        "data, info = registry.load_model(\"my-model\")\n",
        "# Checksum automatically verified!\n",
        "```\n",
        "\n",
        "### HF Hub Offline Workflow\n",
        "\n",
        "```python\n",
        "# Requires pre-downloading models\n",
        "from transformers import AutoModel\n",
        "\n",
        "# First: Download while online\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "model.save_pretrained(\"./local_model\")\n",
        "\n",
        "# Later: Load from local cache\n",
        "model = AutoModel.from_pretrained(\"./local_model\", local_files_only=True)\n",
        "```\n",
        "'''\n",
        "display(Markdown(offline_demo))"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 26: Storage Size Comparison\n",
        "def get_dir_size(path):\n",
        "    \"\"\"Get total size of a directory in bytes.\"\"\"\n",
        "    total = 0\n",
        "    if os.path.isfile(path):\n",
        "        return os.path.getsize(path)\n",
        "    if not os.path.exists(path):\n",
        "        return 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total += os.path.getsize(fp)\n",
        "    return total\n",
        "\n",
        "def count_files(path):\n",
        "    \"\"\"Count files in a directory.\"\"\"\n",
        "    if os.path.isfile(path):\n",
        "        return 1\n",
        "    if not os.path.exists(path):\n",
        "        return 0\n",
        "    count = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        count += len(filenames)\n",
        "    return count\n",
        "\n",
        "print('Storage Comparison')\n",
        "print('=' * 60)\n",
        "\n",
        "# SynaDB\n",
        "if os.path.exists(synadb_path):\n",
        "    size = get_dir_size(synadb_path)\n",
        "    files = count_files(synadb_path)\n",
        "    print(f'SynaDB: {size / (1024 * 1024):.2f} MB ({files} file)')\n",
        "\n",
        "# HF Cache\n",
        "if os.path.exists(hf_cache_path):\n",
        "    size = get_dir_size(hf_cache_path)\n",
        "    files = count_files(hf_cache_path)\n",
        "    print(f'HF Cache: {size / (1024 * 1024):.2f} MB ({files} files)')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('\\nNote: SynaDB stores everything in a single portable file.')\n",
        "print('HF Hub uses a complex directory structure with many files.')"
    ]))
    
    return cells

def add_hf_results_cells(cells):
    """Add results summary cells for HF notebook."""
    cells.append(create_markdown_cell([
        "## üìä Results Summary <a id=\"results\"></a>\n",
        "\n",
        "Summarizing the comparison between SynaDB and Hugging Face Hub."
    ]))
    
    cells.append(create_code_cell([
        "# Cell 28: Results Summary\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "summary = '''\n",
        "### Feature Comparison Summary\n",
        "\n",
        "| Feature | SynaDB | Hugging Face Hub |\n",
        "|---------|--------|------------------|\n",
        "| **Storage type** | Single file | Cloud + local cache |\n",
        "| **Offline support** | ‚úÖ Full | ‚ö†Ô∏è Cache only |\n",
        "| **Integrity verification** | ‚úÖ SHA-256 | ‚ùå None |\n",
        "| **Version management** | ‚úÖ Sequential | ‚úÖ Git-based |\n",
        "| **Stage management** | ‚úÖ Built-in | ‚ö†Ô∏è Manual tags |\n",
        "| **Community sharing** | ‚ùå Local only | ‚úÖ Excellent |\n",
        "| **Model discovery** | ‚ùå None | ‚úÖ Hub search |\n",
        "| **Pre-trained models** | ‚ùå None | ‚úÖ Thousands |\n",
        "| **Setup complexity** | ‚úÖ Zero config | ‚ö†Ô∏è Auth required |\n",
        "| **Cost** | ‚úÖ Free | ‚ö†Ô∏è Paid for private |\n",
        "\n",
        "### When to Use Each\n",
        "\n",
        "**Use SynaDB when:**\n",
        "- Developing locally without network\n",
        "- Deploying to edge devices\n",
        "- Working in air-gapped environments\n",
        "- Need integrity verification\n",
        "- Want simple, portable storage\n",
        "\n",
        "**Use HF Hub when:**\n",
        "- Sharing models with the community\n",
        "- Using pre-trained models\n",
        "- Collaborating with teams\n",
        "- Need model cards and documentation\n",
        "- Want cloud-based storage\n",
        "'''\n",
        "display(Markdown(summary))"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 29: Performance Summary Chart\n",
        "# Create comparison visualization\n",
        "categories = ['Offline', 'Integrity', 'Simplicity', 'Sharing', 'Discovery']\n",
        "synadb_scores = [1.0, 1.0, 1.0, 0.0, 0.0]\n",
        "hf_scores = [0.3, 0.0, 0.5, 1.0, 1.0]\n",
        "\n",
        "x = np.arange(len(categories))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(x - width/2, synadb_scores, width, label='SynaDB', color=COLORS['synadb'])\n",
        "bars2 = ax.bar(x + width/2, hf_scores, width, label='HF Hub', color=COLORS['competitor'])\n",
        "\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('SynaDB vs Hugging Face Hub - Feature Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories)\n",
        "ax.set_ylim(0, 1.2)\n",
        "ax.legend()\n",
        "ax.set_yticks([0, 0.5, 1])\n",
        "ax.set_yticklabels(['None', 'Partial', 'Full'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
    ]))
    
    return cells

def add_hf_conclusion_cells(cells):
    """Add conclusion cells for HF notebook."""
    cells.append(create_markdown_cell([
        "## üéØ Conclusions <a id=\"conclusions\"></a>"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 31: Conclusions\n",
        "conclusion_box(\n",
        "    title='Key Takeaways',\n",
        "    points=[\n",
        "        'SynaDB excels for local, offline, and edge deployment scenarios',\n",
        "        'SHA-256 checksums provide strong integrity guarantees',\n",
        "        'Single-file storage simplifies deployment and backup',\n",
        "        'HF Hub is unmatched for community sharing and pre-trained models',\n",
        "        'Both tools can complement each other in a workflow',\n",
        "        'Use SynaDB for development, HF Hub for distribution'\n",
        "    ],\n",
        "    summary='SynaDB and HF Hub serve different needs - use both for a complete workflow.'\n",
        ")"
    ]))
    
    cells.append(create_code_cell([
        "# Cell 32: Cleanup\n",
        "import shutil\n",
        "try:\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(f'‚úì Cleaned up temp directory: {temp_dir}')\n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è Could not clean up: {e}')"
    ]))
    
    cells.append(create_markdown_cell([
        "---\n",
        "\n",
        "**Next Steps:**\n",
        "- Explore [LLM Framework integrations](../llm_frameworks/) for RAG applications\n",
        "- Check out [End-to-End Pipeline](../specialized/18_end_to_end_pipeline.ipynb) for complete ML workflows\n",
        "- See [GPU Performance](../specialized/15_gpu_performance.ipynb) for high-performance training"
    ]))
    
    return cells

def build_hf_notebook():
    """Build the complete 11_huggingface_hub.ipynb notebook."""
    cells = generate_11_huggingface_hub()
    cells = add_hf_setup_cells(cells)
    cells = add_transformer_storage_cells(cells)
    cells = add_load_time_cells(cells)
    cells = add_hf_version_management_cells(cells)
    cells = add_fine_tuned_cells(cells)
    cells = add_offline_cells(cells)
    cells = add_hf_results_cells(cells)
    cells = add_hf_conclusion_cells(cells)
    
    notebook = {
        "cells": cells,
        "metadata": {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": "python3"
            },
            "language_info": {
                "name": "python",
                "version": "3.9.0"
            }
        },
        "nbformat": 4,
        "nbformat_minor": 4
    }
    
    with open('11_huggingface_hub.ipynb', 'w') as f:
        json.dump(notebook, f, indent=1)
    
    print(f"Generated 11_huggingface_hub.ipynb with {len(cells)} cells")

# Main execution
if __name__ == "__main__":
    build_complete_notebook()
    build_hf_notebook()
