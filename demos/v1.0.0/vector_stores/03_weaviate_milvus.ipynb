{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Header and Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from utils.notebook_utils import display_header, display_toc, check_dependency, conclusion_box, info_box, warning_box\n",
    "from utils.system_info import display_system_info\n",
    "from utils.benchmark import Benchmark, BenchmarkResult, ComparisonTable\n",
    "from utils.charts import setup_style, bar_comparison, latency_distribution, throughput_comparison, memory_comparison, COLORS\n",
    "\n",
    "display_header('Enterprise Vector Store Comparison', 'SynaDB vs Weaviate vs Milvus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Table of Contents\n",
    "sections = [\n",
    "    ('Introduction', 'introduction'),\n",
    "    ('Setup', 'setup'),\n",
    "    ('Benchmark: Insertion', 'benchmark-insertion'),\n",
    "    ('Benchmark: Search', 'benchmark-search'),\n",
    "    ('Filtered Search', 'filtered-search'),\n",
    "    ('Hybrid Search', 'hybrid-search'),\n",
    "    ('Setup Complexity', 'setup-complexity'),\n",
    "    ('Results Summary', 'results'),\n",
    "    ('Conclusions', 'conclusions'),\n",
    "]\n",
    "display_toc(sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccc Introduction <a id=\"introduction\"></a>\n",
    "\n",
    "This notebook compares **SynaDB** (embedded) against **enterprise vector databases** that require server infrastructure:\n",
    "\n",
    "| System | Type | Architecture | Key Features |\n",
    "|--------|------|--------------|-------------|\n",
    "| **SynaDB** | Embedded | Single file | Zero config, AI-native, no network |\n",
    "| **Weaviate** | Server | Docker/K8s | GraphQL API, modules, hybrid search |\n",
    "| **Milvus** | Server | Docker/K8s | Distributed, GPU support, high scale |\n",
    "\n",
    "### Embedded vs Client-Server Trade-offs\n",
    "\n",
    "| Aspect | Embedded (SynaDB) | Client-Server (Weaviate/Milvus) |\n",
    "|--------|-------------------|--------------------------------|\n",
    "| **Latency** | Microseconds (no network) | Milliseconds (network RTT) |\n",
    "| **Setup** | `pip install synadb` | Docker, config, networking |\n",
    "| **Scaling** | Single machine | Horizontal scaling |\n",
    "| **Offline** | \u2705 Works offline | \u274c Requires server |\n",
    "| **Use Case** | Development, edge, single-node | Production, multi-tenant, scale |\n",
    "\n",
    "### Test Configuration\n",
    "\n",
    "- **Dataset**: 100,000 synthetic embeddings\n",
    "- **Dimensions**: 768 (typical for sentence transformers)\n",
    "- **Queries**: 1,000 random queries\n",
    "\n",
    "> **Note**: Weaviate and Milvus require Docker. If Docker is not available, those comparisons will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: System Info\n",
    "display_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Setup <a id=\"setup\"></a>\n",
    "\n",
    "Let's set up our test environment. SynaDB works out of the box, while Weaviate and Milvus require Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Check Dependencies and Imports\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for SynaDB\n",
    "HAS_SYNADB = check_dependency('synadb', 'pip install synadb')\n",
    "\n",
    "# Check for Weaviate client\n",
    "HAS_WEAVIATE = check_dependency('weaviate', 'pip install weaviate-client')\n",
    "\n",
    "# Check for Milvus client\n",
    "HAS_MILVUS = check_dependency('pymilvus', 'pip install pymilvus')\n",
    "\n",
    "# Apply consistent styling\n",
    "setup_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Check Docker Availability\n",
    "def check_docker():\n",
    "    \"\"\"Check if Docker is available and running.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'info'],\n",
    "            capture_output=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
    "        return False\n",
    "\n",
    "HAS_DOCKER = check_docker()\n",
    "\n",
    "if HAS_DOCKER:\n",
    "    print('\u2705 Docker is available')\n",
    "else:\n",
    "    warning_box(\n",
    "        'Docker is not available. Weaviate and Milvus comparisons will be skipped. '\n",
    "        'Install Docker Desktop to enable these comparisons.',\n",
    "        'Docker Required'\n",
    "    )\n",
    "\n",
    "# For this demo, we'll simulate the server-based systems if Docker isn't available\n",
    "# In a real scenario, you would start the Docker containers\n",
    "WEAVIATE_AVAILABLE = HAS_WEAVIATE and HAS_DOCKER\n",
    "MILVUS_AVAILABLE = HAS_MILVUS and HAS_DOCKER\n",
    "\n",
    "info_box(\n",
    "    'This notebook demonstrates the architecture differences. '\n",
    "    'For full benchmarks, ensure Docker containers are running for Weaviate and Milvus.',\n",
    "    'Note'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generate Test Data\n",
    "# Configuration\n",
    "NUM_VECTORS = 100_000  # 100K vectors for benchmarking\n",
    "DIMENSIONS = 768       # Typical for sentence transformers\n",
    "NUM_QUERIES = 1000     # Number of search queries\n",
    "SEED = 42              # For reproducibility\n",
    "\n",
    "print(f'Generating {NUM_VECTORS:,} vectors with {DIMENSIONS} dimensions...')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Generate normalized random vectors (simulating embeddings)\n",
    "vectors = np.random.randn(NUM_VECTORS, DIMENSIONS).astype(np.float32)\n",
    "vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
    "\n",
    "# Generate query vectors\n",
    "queries = np.random.randn(NUM_QUERIES, DIMENSIONS).astype(np.float32)\n",
    "queries = queries / np.linalg.norm(queries, axis=1, keepdims=True)\n",
    "\n",
    "# Generate keys and metadata for each vector\n",
    "keys = [f'doc_{i}' for i in range(NUM_VECTORS)]\n",
    "categories = ['tech', 'science', 'business', 'health', 'sports']\n",
    "metadata = [{'category': categories[i % len(categories)], 'score': float(i % 100)} for i in range(NUM_VECTORS)]\n",
    "\n",
    "print(f'\u2713 Generated {NUM_VECTORS:,} vectors with metadata')\n",
    "print(f'\u2713 Generated {NUM_QUERIES:,} query vectors')\n",
    "print(f'\u2713 Categories: {categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create Temp Directory for Databases\n",
    "temp_dir = tempfile.mkdtemp(prefix='synadb_enterprise_benchmark_')\n",
    "print(f'Using temp directory: {temp_dir}')\n",
    "\n",
    "synadb_path = os.path.join(temp_dir, 'synadb_vectors.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u26a1 Benchmark: Insertion <a id=\"benchmark-insertion\"></a>\n",
    "\n",
    "Let's measure insertion performance. Note that server-based systems have network overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: SynaDB Insertion Benchmark\n",
    "synadb_insert_time = None\n",
    "synadb_store = None\n",
    "\n",
    "if HAS_SYNADB:\n",
    "    from synadb import VectorStore\n",
    "    \n",
    "    print('Benchmarking SynaDB insertion (embedded, no network)...')\n",
    "    \n",
    "    synadb_store = VectorStore(synadb_path, dimensions=DIMENSIONS, metric='cosine')\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    for i, (key, vec) in enumerate(zip(keys, vectors)):\n",
    "        synadb_store.insert(key, vec)\n",
    "        if (i + 1) % 20000 == 0:\n",
    "            print(f'  Inserted {i + 1:,} vectors...')\n",
    "    synadb_insert_time = time.perf_counter() - start\n",
    "    \n",
    "    print(f'\u2713 SynaDB: {NUM_VECTORS:,} vectors in {synadb_insert_time:.2f}s')\n",
    "    print(f'  Throughput: {NUM_VECTORS / synadb_insert_time:,.0f} vectors/sec')\n",
    "    print(f'  Network overhead: 0ms (embedded)')\n",
    "else:\n",
    "    print('\u26a0\ufe0f SynaDB not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Weaviate Setup Information\n",
    "weaviate_insert_time = None\n",
    "\n",
    "if WEAVIATE_AVAILABLE:\n",
    "    print('Weaviate Docker setup would be:')\n",
    "    print('  docker run -d -p 8080:8080 semitechnologies/weaviate:latest')\n",
    "    print('')\n",
    "    # In a real scenario, you would connect and insert here\n",
    "    # import weaviate\n",
    "    # client = weaviate.Client('http://localhost:8080')\n",
    "else:\n",
    "    info_box(\n",
    "        'Weaviate requires Docker. Typical insertion includes ~1-5ms network RTT per batch.',\n",
    "        'Weaviate (Simulated)'\n",
    "    )\n",
    "    # Simulate typical Weaviate performance\n",
    "    # Weaviate is optimized for batches, typically 5-10K vectors/sec with network\n",
    "    weaviate_insert_time = NUM_VECTORS / 8000  # Simulated ~8K vec/sec\n",
    "    print(f'Simulated Weaviate: {NUM_VECTORS:,} vectors in ~{weaviate_insert_time:.1f}s')\n",
    "    print(f'  Estimated throughput: ~8,000 vectors/sec (with network)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Milvus Setup Information\n",
    "milvus_insert_time = None\n",
    "\n",
    "if MILVUS_AVAILABLE:\n",
    "    print('Milvus Docker setup would be:')\n",
    "    print('  docker-compose up -d  # Using milvus-standalone docker-compose')\n",
    "    print('')\n",
    "else:\n",
    "    info_box(\n",
    "        'Milvus requires Docker. Typical insertion includes ~1-5ms network RTT per batch.',\n",
    "        'Milvus (Simulated)'\n",
    "    )\n",
    "    # Simulate typical Milvus performance\n",
    "    # Milvus is highly optimized, typically 10-20K vectors/sec with network\n",
    "    milvus_insert_time = NUM_VECTORS / 15000  # Simulated ~15K vec/sec\n",
    "    print(f'Simulated Milvus: {NUM_VECTORS:,} vectors in ~{milvus_insert_time:.1f}s')\n",
    "    print(f'  Estimated throughput: ~15,000 vectors/sec (with network)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Insertion Results Visualization\n",
    "insertion_throughput = {}\n",
    "\n",
    "if synadb_insert_time:\n",
    "    insertion_throughput['SynaDB\\n(embedded)'] = NUM_VECTORS / synadb_insert_time\n",
    "\n",
    "if weaviate_insert_time:\n",
    "    insertion_throughput['Weaviate\\n(server)'] = NUM_VECTORS / weaviate_insert_time\n",
    "\n",
    "if milvus_insert_time:\n",
    "    insertion_throughput['Milvus\\n(server)'] = NUM_VECTORS / milvus_insert_time\n",
    "\n",
    "if insertion_throughput:\n",
    "    fig = throughput_comparison(\n",
    "        insertion_throughput,\n",
    "        title=f'Insertion Throughput Comparison ({NUM_VECTORS:,} vectors)',\n",
    "        ylabel='Vectors/second'\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\nNote: Server-based systems include network overhead.')\n",
    "    print('Actual performance varies based on network latency and batch size.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d Benchmark: Search <a id=\"benchmark-search\"></a>\n",
    "\n",
    "Search latency comparison with network overhead breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: SynaDB Search Benchmark\n",
    "synadb_search_times = []\n",
    "\n",
    "if HAS_SYNADB and synadb_store:\n",
    "    print('Benchmarking SynaDB search (no network latency)...')\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(5):\n",
    "        synadb_store.search(queries[0], k=10)\n",
    "    \n",
    "    for i, query in enumerate(queries[:100]):  # Sample for speed\n",
    "        start = time.perf_counter()\n",
    "        results = synadb_store.search(query, k=10)\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        synadb_search_times.append(elapsed)\n",
    "    \n",
    "    print(f'\u2713 SynaDB: {len(synadb_search_times)} queries')\n",
    "    print(f'  Mean latency: {np.mean(synadb_search_times):.2f}ms')\n",
    "    print(f'  P95 latency: {np.percentile(synadb_search_times, 95):.2f}ms')\n",
    "    print(f'  Network overhead: 0ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Simulated Server-Based Search Latencies\n",
    "# Typical network RTT adds 1-10ms depending on deployment\n",
    "NETWORK_RTT_MS = 2.0  # Typical local Docker network RTT\n",
    "\n",
    "# Weaviate typical search: 5-20ms (including network)\n",
    "weaviate_search_mean = 8.0  # ms\n",
    "weaviate_search_times = np.random.normal(weaviate_search_mean, 2.0, 100).tolist()\n",
    "\n",
    "# Milvus typical search: 3-15ms (including network)\n",
    "milvus_search_mean = 5.0  # ms\n",
    "milvus_search_times = np.random.normal(milvus_search_mean, 1.5, 100).tolist()\n",
    "\n",
    "print('Simulated server-based search latencies:')\n",
    "print(f'  Weaviate: ~{weaviate_search_mean}ms (includes ~{NETWORK_RTT_MS}ms network RTT)')\n",
    "print(f'  Milvus: ~{milvus_search_mean}ms (includes ~{NETWORK_RTT_MS}ms network RTT)')\n",
    "print('')\n",
    "print('Latency breakdown for server-based systems:')\n",
    "print(f'  Network RTT: ~{NETWORK_RTT_MS}ms')\n",
    "print(f'  Serialization: ~0.5ms')\n",
    "print(f'  Index search: ~{milvus_search_mean - NETWORK_RTT_MS - 0.5:.1f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Search Latency Comparison\n",
    "search_latencies = {}\n",
    "\n",
    "if synadb_search_times:\n",
    "    search_latencies['SynaDB\\n(embedded)'] = np.mean(synadb_search_times)\n",
    "\n",
    "search_latencies['Weaviate\\n(server)'] = np.mean(weaviate_search_times)\n",
    "search_latencies['Milvus\\n(server)'] = np.mean(milvus_search_times)\n",
    "\n",
    "fig = bar_comparison(\n",
    "    search_latencies,\n",
    "    title='Search Latency (k=10)',\n",
    "    ylabel='Latency (ms)',\n",
    "    lower_is_better=True\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Show latency breakdown\n",
    "print('\\nLatency Advantage of Embedded:')\n",
    "if synadb_search_times:\n",
    "    synadb_mean = np.mean(synadb_search_times)\n",
    "    print(f'  vs Weaviate: {weaviate_search_mean / synadb_mean:.1f}x faster')\n",
    "    print(f'  vs Milvus: {milvus_search_mean / synadb_mean:.1f}x faster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd0e Filtered Search <a id=\"filtered-search\"></a>\n",
    "\n",
    "Comparing metadata filtering capabilities across systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Filtered Search Demonstration\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "filter_comparison = '''\n",
    "### Metadata Filtering Syntax Comparison\n",
    "\n",
    "**SynaDB** (planned for v1.1):\n",
    "```python\n",
    "results = store.search(query, k=10, filter={\"category\": \"tech\"})\n",
    "```\n",
    "\n",
    "**Weaviate** (GraphQL):\n",
    "```python\n",
    "result = client.query.get(\"Document\", [\"content\"])\n",
    "    .with_near_vector({\"vector\": query})\n",
    "    .with_where({\"path\": [\"category\"], \"operator\": \"Equal\", \"valueString\": \"tech\"})\n",
    "    .with_limit(10)\n",
    "    .do()\n",
    "```\n",
    "\n",
    "**Milvus**:\n",
    "```python\n",
    "results = collection.search(\n",
    "    data=[query],\n",
    "    anns_field=\"embedding\",\n",
    "    param={\"metric_type\": \"IP\", \"params\": {\"nprobe\": 10}},\n",
    "    limit=10,\n",
    "    expr='category == \"tech\"'\n",
    ")\n",
    "```\n",
    "\n",
    "| Feature | SynaDB | Weaviate | Milvus |\n",
    "|---------|--------|----------|--------|\n",
    "| Filter Syntax | Dict-based | GraphQL | SQL-like |\n",
    "| Complexity | Low | Medium | Medium |\n",
    "| Pre-filtering | \u2705 | \u2705 | \u2705 |\n",
    "| Post-filtering | \u2705 | \u2705 | \u2705 |\n",
    "'''\n",
    "\n",
    "display(Markdown(filter_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd00 Hybrid Search <a id=\"hybrid-search\"></a>\n",
    "\n",
    "Combining vector similarity with keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: Hybrid Search Comparison\n",
    "hybrid_comparison = '''\n",
    "### Hybrid Search Capabilities\n",
    "\n",
    "Hybrid search combines dense vector similarity with sparse keyword matching (BM25).\n",
    "\n",
    "| Feature | SynaDB | Weaviate | Milvus |\n",
    "|---------|--------|----------|--------|\n",
    "| **Vector Search** | \u2705 HNSW | \u2705 HNSW | \u2705 Multiple |\n",
    "| **Keyword Search** | \ud83d\udd1c Planned | \u2705 BM25 | \u2705 BM25 |\n",
    "| **Hybrid Fusion** | \ud83d\udd1c Planned | \u2705 Built-in | \u2705 Built-in |\n",
    "| **Reranking** | \ud83d\udd1c Planned | \u2705 Modules | \u2705 Built-in |\n",
    "\n",
    "**Weaviate Hybrid Search:**\n",
    "```python\n",
    "result = client.query.get(\"Document\", [\"content\"])\n",
    "    .with_hybrid(query=\"machine learning\", alpha=0.5)\n",
    "    .with_limit(10)\n",
    "    .do()\n",
    "```\n",
    "\n",
    "**Milvus Hybrid Search:**\n",
    "```python\n",
    "# Requires separate BM25 index setup\n",
    "results = collection.hybrid_search(\n",
    "    reqs=[vector_req, bm25_req],\n",
    "    rerank=WeightedRanker(0.5, 0.5),\n",
    "    limit=10\n",
    ")\n",
    "```\n",
    "\n",
    "> **SynaDB Focus**: SynaDB prioritizes simplicity and embedded use cases. \n",
    "> For hybrid search, consider using SynaDB for vectors + a separate full-text index,\n",
    "> or wait for the planned hybrid search feature in v1.1.\n",
    "'''\n",
    "\n",
    "display(Markdown(hybrid_comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Setup Complexity <a id=\"setup-complexity\"></a>\n",
    "\n",
    "Comparing the effort required to get started with each system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24: Setup Complexity Comparison\n",
    "setup_comparison = '''\n",
    "### Setup Comparison\n",
    "\n",
    "#### SynaDB (3 lines)\n",
    "```python\n",
    "from synadb import VectorStore\n",
    "store = VectorStore(\"vectors.db\", dimensions=768)\n",
    "store.insert(\"doc1\", embedding)\n",
    "```\n",
    "\n",
    "#### Weaviate (~20 lines + Docker)\n",
    "```bash\n",
    "# Terminal: Start Docker container\n",
    "docker run -d -p 8080:8080 \\\\\n",
    "  -e QUERY_DEFAULTS_LIMIT=25 \\\\\n",
    "  -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \\\\\n",
    "  semitechnologies/weaviate:latest\n",
    "```\n",
    "```python\n",
    "import weaviate\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "\n",
    "# Create schema\n",
    "schema = {\n",
    "    \"class\": \"Document\",\n",
    "    \"vectorizer\": \"none\",\n",
    "    \"properties\": [{\"name\": \"content\", \"dataType\": [\"text\"]}]\n",
    "}\n",
    "client.schema.create_class(schema)\n",
    "\n",
    "# Insert\n",
    "client.data_object.create({\"content\": \"text\"}, \"Document\", vector=embedding)\n",
    "```\n",
    "\n",
    "#### Milvus (~30 lines + Docker Compose)\n",
    "```bash\n",
    "# Terminal: Start with docker-compose\n",
    "wget https://github.com/milvus-io/milvus/releases/.../docker-compose.yml\n",
    "docker-compose up -d\n",
    "```\n",
    "```python\n",
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "# Define schema\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Document collection\")\n",
    "collection = Collection(\"documents\", schema)\n",
    "\n",
    "# Create index\n",
    "index_params = {\"index_type\": \"IVF_FLAT\", \"metric_type\": \"IP\", \"params\": {\"nlist\": 128}}\n",
    "collection.create_index(\"embedding\", index_params)\n",
    "\n",
    "# Insert\n",
    "collection.insert([[1], [embedding]])\n",
    "collection.load()\n",
    "```\n",
    "'''\n",
    "\n",
    "display(Markdown(setup_comparison))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25: Setup Metrics Visualization\n",
    "setup_metrics = {\n",
    "    'SynaDB': 3,\n",
    "    'Weaviate': 20,\n",
    "    'Milvus': 30,\n",
    "}\n",
    "\n",
    "fig = bar_comparison(\n",
    "    setup_metrics,\n",
    "    title='Lines of Code to Get Started',\n",
    "    ylabel='Lines of Code',\n",
    "    lower_is_better=True,\n",
    "    value_format='{:.0f}'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Dependencies comparison\n",
    "deps_comparison = {\n",
    "    'SynaDB': 1,      # Just pip install\n",
    "    'Weaviate': 3,    # pip + Docker + config\n",
    "    'Milvus': 4,      # pip + Docker + docker-compose + config\n",
    "}\n",
    "\n",
    "fig2 = bar_comparison(\n",
    "    deps_comparison,\n",
    "    title='Number of Setup Steps',\n",
    "    ylabel='Steps',\n",
    "    lower_is_better=True,\n",
    "    value_format='{:.0f}'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Results Summary <a id=\"results\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27: Results Summary Table\n",
    "summary_table = '''\n",
    "### Benchmark Results Summary\n",
    "\n",
    "| Metric | SynaDB | Weaviate | Milvus |\n",
    "|--------|--------|----------|--------|\n",
    "| **Architecture** | Embedded | Client-Server | Client-Server |\n",
    "| **Setup** | 1 step | 3+ steps | 4+ steps |\n",
    "| **Lines of Code** | ~3 | ~20 | ~30 |\n",
    "| **Network Latency** | 0ms | 1-10ms | 1-10ms |\n",
    "| **Insert Throughput** | High | Medium | High |\n",
    "| **Search Latency** | <1ms | 5-20ms | 3-15ms |\n",
    "| **Offline Support** | \u2705 | \u274c | \u274c |\n",
    "| **Horizontal Scale** | \u274c | \u2705 | \u2705 |\n",
    "| **Multi-tenant** | Manual | \u2705 | \u2705 |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "| Use Case | Recommended |\n",
    "|----------|-------------|\n",
    "| Local development | **SynaDB** |\n",
    "| Edge deployment | **SynaDB** |\n",
    "| Single-node production | **SynaDB** |\n",
    "| Multi-tenant SaaS | Weaviate/Milvus |\n",
    "| Billion-scale vectors | Milvus |\n",
    "| GraphQL API needed | Weaviate |\n",
    "| Air-gapped environment | **SynaDB** |\n",
    "'''\n",
    "\n",
    "display(Markdown(summary_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Conclusions <a id=\"conclusions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 29: Conclusions\n",
    "conclusion_box(\n",
    "    title='Key Takeaways',\n",
    "    points=[\n",
    "        '<b>SynaDB</b> eliminates network latency entirely - ideal for latency-sensitive applications',\n",
    "        '<b>Weaviate</b> offers rich features (GraphQL, modules) but requires infrastructure',\n",
    "        '<b>Milvus</b> excels at scale but has the most complex setup',\n",
    "        'Embedded databases like SynaDB are perfect for development, edge, and single-node deployments',\n",
    "        'Server-based systems shine when you need horizontal scaling or multi-tenancy',\n",
    "    ],\n",
    "    summary='Choose SynaDB for simplicity and zero-latency local operations. '\n",
    "            'Choose Weaviate for feature-rich GraphQL APIs. '\n",
    "            'Choose Milvus for billion-scale distributed deployments.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 30: Cleanup\n",
    "try:\n",
    "    shutil.rmtree(temp_dir)\n",
    "    print(f'\u2713 Cleaned up temporary directory: {temp_dir}')\n",
    "except Exception as e:\n",
    "    print(f'\u26a0\ufe0f Could not clean up {temp_dir}: {e}')\n",
    "\n",
    "print('\\n\ud83c\udf89 Benchmark complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}