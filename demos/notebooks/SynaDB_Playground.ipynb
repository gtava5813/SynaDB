{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SynaDB Playground\n",
        "\n",
        "**Don't trust our claims. Verify them yourself.**\n",
        "\n",
        "This notebook runs real benchmarks with the actual SynaDB library. We use **relative comparisons** that work on any hardware.\n",
        "\n",
        "| Benchmark | Comparison |\n",
        "|-----------|------------|\n",
        "| Mmap vs VectorStore | MmapVectorStore batch insert faster |\n",
        "| GWI vs HNSW | GWI builds faster |\n",
        "| HNSW vs Brute Force | HNSW search faster |\n",
        "| Schema-Free | 4 data types stored correctly |\n",
        "| Crash Recovery | Data integrity after reopen |\n",
        "| Tensor Extraction | Direct NumPy from history |\n",
        "\n",
        "---\n",
        "**Links:** [GitHub](https://github.com/gtava5813/SynaDB) | [Docs](https://github.com/gtava5813/SynaDB/wiki) | [PyPI](https://pypi.org/project/synadb/)"
      ],
      "metadata": {"id": "header"}
    },
    {
      "cell_type": "markdown",
      "source": ["## Setup"],
      "metadata": {"id": "setup-header"}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {"id": "install"},
      "outputs": [],
      "source": [
        "# Install SynaDB\n",
        "!pip install -q synadb numpy\n",
        "\n",
        "import synadb\n",
        "print(f\"SynaDB {synadb.__version__} installed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test Scale Configuration { run: \"auto\" }\n",
        "SCALE = \"medium\" #@param [\"small\", \"medium\", \"large\"]\n",
        "\n",
        "SCALES = {\n",
        "    \"small\":  {\"records\": 10_000,    \"vectors\": 1_000,   \"dims\": 384},\n",
        "    \"medium\": {\"records\": 100_000,   \"vectors\": 10_000,  \"dims\": 768},\n",
        "    \"large\":  {\"records\": 1_000_000, \"vectors\": 50_000,  \"dims\": 768},\n",
        "}\n",
        "\n",
        "cfg = SCALES[SCALE]\n",
        "print(f\"Scale: {SCALE.upper()} | Records: {cfg['records']:,} | Vectors: {cfg['vectors']:,} | Dims: {cfg['dims']}\")\n",
        "\n",
        "# Results collector\n",
        "RESULTS = {}"
      ],
      "metadata": {"id": "config"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common imports\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from synadb import SynaDB, VectorStore\n",
        "\n",
        "def cleanup(*paths):\n",
        "    for p in paths:\n",
        "        if os.path.exists(p):\n",
        "            os.remove(p)"
      ],
      "metadata": {"id": "imports"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 1: Core Database Performance\n**Relative: Read faster than write (in-memory index)**"],
      "metadata": {"id": "write-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "n = cfg[\"records\"]\n",
        "db_path = \"bench_write.db\"\n",
        "cleanup(db_path)\n",
        "\n",
        "db = SynaDB(db_path, sync_on_write=False)\n",
        "\n",
        "print(f\"Writing {n:,} records...\")\n",
        "start = time.perf_counter()\n",
        "for i in range(n):\n",
        "    db.put_float(f\"sensor/temp/{i}\", 20.0 + (i % 100) * 0.1)\n",
        "write_time = time.perf_counter() - start\n",
        "write_rate = n / write_time\n",
        "\n",
        "print(f\"Write rate: {write_rate:,.0f} ops/sec\")\n",
        "print(f\"File: {os.path.getsize(db_path) / 1e6:.1f} MB\")\n",
        "\n",
        "# Now test read performance\n",
        "read_count = min(n, 100_000)\n",
        "indices = np.random.randint(0, n, size=read_count)\n",
        "\n",
        "print(f\"\\nReading {read_count:,} random records...\")\n",
        "start = time.perf_counter()\n",
        "for i in indices:\n",
        "    _ = db.get_float(f\"sensor/temp/{i}\")\n",
        "read_time = time.perf_counter() - start\n",
        "read_rate = read_count / read_time\n",
        "\n",
        "read_vs_write = read_rate / write_rate if write_rate > 0 else 0\n",
        "core_pass = read_rate > write_rate\n",
        "\n",
        "print(f\"Read rate: {read_rate:,.0f} ops/sec\")\n",
        "print(f\"\\nRead vs Write: {read_vs_write:.1f}x | {'PASS' if core_pass else 'FAIL'}\")\n",
        "db.close()\n",
        "\n",
        "RESULTS['core_db'] = {'write_rate': write_rate, 'read_rate': read_rate, 'speedup': read_vs_write, 'pass': core_pass}"
      ],
      "metadata": {"id": "write-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 2: Vector Store + HNSW\n**Relative: HNSW search faster than brute force**"],
      "metadata": {"id": "vector-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "n_vec = cfg[\"vectors\"]\n",
        "dims = cfg[\"dims\"]\n",
        "vec_path = \"bench_vectors.db\"\n",
        "cleanup(vec_path)\n",
        "\n",
        "store = VectorStore(vec_path, dimensions=dims)\n",
        "vectors = np.random.randn(n_vec, dims).astype(np.float32)\n",
        "\n",
        "print(f\"Inserting {n_vec:,} vectors ({dims} dims)...\")\n",
        "start = time.perf_counter()\n",
        "for i, vec in enumerate(vectors):\n",
        "    store.insert(f\"doc_{i}\", vec)\n",
        "insert_time = time.perf_counter() - start\n",
        "insert_rate = n_vec / insert_time\n",
        "\n",
        "query = np.random.randn(dims).astype(np.float32)\n",
        "\n",
        "# Brute force search (before index)\n",
        "print(\"Brute force search...\")\n",
        "start = time.perf_counter()\n",
        "brute_results = store.search(query, k=10)\n",
        "brute_ms = (time.perf_counter() - start) * 1000\n",
        "\n",
        "print(f\"Building HNSW index...\")\n",
        "start = time.perf_counter()\n",
        "store.build_index()\n",
        "build_time = time.perf_counter() - start\n",
        "\n",
        "# HNSW search (after index)\n",
        "print(\"HNSW search...\")\n",
        "start = time.perf_counter()\n",
        "hnsw_results = store.search(query, k=10)\n",
        "hnsw_ms = (time.perf_counter() - start) * 1000\n",
        "\n",
        "speedup = brute_ms / hnsw_ms if hnsw_ms > 0 else 0\n",
        "vector_pass = hnsw_ms < brute_ms\n",
        "\n",
        "print(f\"\\nInsert: {insert_rate:,.0f}/sec | Build: {build_time:.1f}s\")\n",
        "print(f\"Brute force: {brute_ms:.2f}ms | HNSW: {hnsw_ms:.2f}ms | Speedup: {speedup:.1f}x\")\n",
        "print(f\"Result: {'PASS' if vector_pass else 'FAIL'}\")\n",
        "print(f\"Top result: {hnsw_results[0].key} (score: {hnsw_results[0].score:.4f})\")\n",
        "store.close()\n",
        "\n",
        "RESULTS['hnsw_vs_brute'] = {'brute_ms': brute_ms, 'hnsw_ms': hnsw_ms, 'speedup': speedup, 'pass': vector_pass}\n",
        "RESULTS['hnsw_build'] = {'value': build_time, 'unit': 's'}"
      ],
      "metadata": {"id": "vector-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 3: MmapVectorStore vs VectorStore\n**Relative: MmapVectorStore batch insert faster than VectorStore**"],
      "metadata": {"id": "mmap-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from synadb import MmapVectorStore\n",
        "    \n",
        "    mmap_path = \"bench_mmap.mmap\"\n",
        "    cleanup(mmap_path)\n",
        "    \n",
        "    store = MmapVectorStore(mmap_path, dimensions=dims, initial_capacity=n_vec * 2)\n",
        "    keys = [f\"vec_{i}\" for i in range(n_vec)]\n",
        "    \n",
        "    print(f\"MmapVectorStore batch inserting {n_vec:,} vectors...\")\n",
        "    start = time.perf_counter()\n",
        "    store.insert_batch(keys, vectors)\n",
        "    mmap_time = time.perf_counter() - start\n",
        "    mmap_rate = n_vec / mmap_time\n",
        "    store.close()\n",
        "    \n",
        "    # Compare with VectorStore insert rate from earlier\n",
        "    speedup = mmap_rate / insert_rate if insert_rate > 0 else 0\n",
        "    mmap_pass = speedup >= 2  # At least 2x faster\n",
        "    \n",
        "    print(f\"MmapVectorStore: {mmap_rate:,.0f}/sec\")\n",
        "    print(f\"VectorStore: {insert_rate:,.0f}/sec\")\n",
        "    print(f\"Speedup: {speedup:.1f}x | {'PASS' if mmap_pass else 'FAIL'}\")\n",
        "    \n",
        "    RESULTS['mmap_vs_vector'] = {'mmap_rate': mmap_rate, 'vector_rate': insert_rate, 'speedup': speedup, 'pass': mmap_pass}\n",
        "except ImportError:\n",
        "    print(\"MmapVectorStore not available in this version\")\n",
        "    RESULTS['mmap_vs_vector'] = {'speedup': 0, 'pass': None, 'note': 'Not available'}"
      ],
      "metadata": {"id": "mmap-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 4: GWI vs HNSW Build Time\n**Relative: GWI builds faster than HNSW**"],
      "metadata": {"id": "gwi-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from synadb import GravityWellIndex\n",
        "    \n",
        "    gwi_path = \"bench_gwi.gwi\"\n",
        "    cleanup(gwi_path)\n",
        "    \n",
        "    gwi = GravityWellIndex(gwi_path, dimensions=dims)\n",
        "    gwi.initialize(vectors[:1000])\n",
        "    \n",
        "    print(f\"GWI: Inserting {n_vec:,} vectors...\")\n",
        "    start = time.perf_counter()\n",
        "    gwi.insert_batch(keys, vectors)\n",
        "    gwi_time = time.perf_counter() - start\n",
        "    gwi.close()\n",
        "    \n",
        "    speedup = build_time / gwi_time if gwi_time > 0 else 0\n",
        "    gwi_pass = speedup >= 5  # At least 5x faster\n",
        "    \n",
        "    print(f\"GWI build: {gwi_time:.2f}s | HNSW build: {build_time:.2f}s\")\n",
        "    print(f\"Speedup: {speedup:.1f}x | {'PASS' if gwi_pass else 'FAIL'}\")\n",
        "    \n",
        "    RESULTS['gwi_vs_hnsw'] = {'gwi_time': gwi_time, 'hnsw_time': build_time, 'speedup': speedup, 'pass': gwi_pass}\n",
        "except ImportError:\n",
        "    print(\"GravityWellIndex not available in this version\")\n",
        "    RESULTS['gwi_vs_hnsw'] = {'speedup': 0, 'pass': None, 'note': 'Not available'}"
      ],
      "metadata": {"id": "gwi-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 5: Crash Recovery\n**Functional: Full data recovery after reopen**"],
      "metadata": {"id": "recovery-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Reopening database with {n:,} entries...\")\n",
        "start = time.perf_counter()\n",
        "db2 = SynaDB(db_path)\n",
        "recovery_time = time.perf_counter() - start\n",
        "\n",
        "recovery_rate = n / recovery_time\n",
        "\n",
        "# Verify integrity\n",
        "sample = db2.get_float(f\"sensor/temp/{n//2}\")\n",
        "expected = 20.0 + ((n//2) % 100) * 0.1\n",
        "integrity_ok = abs(sample - expected) < 0.001\n",
        "\n",
        "print(f\"Recovery: {recovery_time:.3f}s | Rate: {recovery_rate:,.0f}/sec\")\n",
        "print(f\"Integrity: {'PASS' if integrity_ok else 'FAIL'}\")\n",
        "db2.close()\n",
        "\n",
        "RESULTS['recovery'] = {'rate': recovery_rate, 'time': recovery_time, 'pass': integrity_ok}"
      ],
      "metadata": {"id": "recovery-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 6: Schema-Free Storage\n**Functional: Store any type without migrations**"],
      "metadata": {"id": "schema-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "schema_path = \"bench_schema.db\"\n",
        "cleanup(schema_path)\n",
        "\n",
        "db = SynaDB(schema_path)\n",
        "\n",
        "db.put_float(\"metrics/accuracy\", 0.95)\n",
        "db.put_int(\"metrics/epoch\", 100)\n",
        "db.put_text(\"config/model\", \"bert-base-uncased\")\n",
        "db.put_bytes(\"data/binary\", b\"\\x00\\x01\\x02\\x03\\xff\")\n",
        "\n",
        "# Verify\n",
        "float_ok = db.get_float('metrics/accuracy') == 0.95\n",
        "int_ok = db.get_int('metrics/epoch') == 100\n",
        "text_ok = db.get_text('config/model') == \"bert-base-uncased\"\n",
        "bytes_ok = db.get_bytes('data/binary') == b\"\\x00\\x01\\x02\\x03\\xff\"\n",
        "\n",
        "types_passed = sum([float_ok, int_ok, text_ok, bytes_ok])\n",
        "schema_pass = types_passed == 4\n",
        "\n",
        "print(\"Schema-free storage test:\")\n",
        "print(f\"  Float: {'OK' if float_ok else 'FAIL'} | Int: {'OK' if int_ok else 'FAIL'} | Text: {'OK' if text_ok else 'FAIL'} | Bytes: {'OK' if bytes_ok else 'FAIL'}\")\n",
        "print(f\"Result: {types_passed}/4 types | {'PASS' if schema_pass else 'FAIL'}\")\n",
        "db.close()\n",
        "\n",
        "RESULTS['schema_free'] = {'types': types_passed, 'target': 4, 'pass': schema_pass}"
      ],
      "metadata": {"id": "schema-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Benchmark 7: Tensor Extraction\n**Functional: Direct NumPy tensor extraction**"],
      "metadata": {"id": "tensor-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_path = \"bench_tensor.db\"\n",
        "cleanup(tensor_path)\n",
        "\n",
        "db = SynaDB(tensor_path, sync_on_write=False)\n",
        "\n",
        "ts_count = min(n, 100_000)\n",
        "print(f\"Writing {ts_count:,} time-series values...\")\n",
        "for i in range(ts_count):\n",
        "    db.put_float(\"sensor/temperature\", 20.0 + np.sin(i / 100) * 5)\n",
        "\n",
        "print(\"Extracting as NumPy tensor...\")\n",
        "start = time.perf_counter()\n",
        "tensor = db.get_history_tensor(\"sensor/temperature\")\n",
        "extract_time = time.perf_counter() - start\n",
        "\n",
        "tensor_pass = tensor is not None and len(tensor) == ts_count\n",
        "\n",
        "print(f\"Shape: {tensor.shape} | Dtype: {tensor.dtype}\")\n",
        "print(f\"Size: {tensor.nbytes / 1e6:.2f} MB | Time: {extract_time:.3f}s\")\n",
        "print(f\"Result: {'PASS' if tensor_pass else 'FAIL'}\")\n",
        "db.close()\n",
        "\n",
        "RESULTS['tensor'] = {'count': len(tensor), 'time': extract_time, 'pass': tensor_pass}"
      ],
      "metadata": {"id": "tensor-bench"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n## Summary"],
      "metadata": {"id": "summary-header"}
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleanup all test files\n",
        "cleanup(\"bench_write.db\", \"bench_vectors.db\", \"bench_mmap.mmap\", \n",
        "        \"bench_gwi.gwi\", \"bench_schema.db\", \"bench_tensor.db\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SYNADB RELATIVE BENCHMARK RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Scale: {SCALE.upper()} | Records: {cfg['records']:,} | Vectors: {cfg['vectors']:,}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Benchmark':<25} {'Result':<25} {'Status':<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Core DB (Read vs Write)\n",
        "r = RESULTS.get('core_db', {})\n",
        "print(f\"{'Read vs Write':<25} {r.get('speedup', 0):>20.1f}x faster {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# HNSW vs Brute Force\n",
        "r = RESULTS.get('hnsw_vs_brute', {})\n",
        "print(f\"{'HNSW vs Brute Force':<25} {r.get('speedup', 0):>20.1f}x faster {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# MmapVectorStore vs VectorStore\n",
        "r = RESULTS.get('mmap_vs_vector', {})\n",
        "if r.get('note'):\n",
        "    print(f\"{'Mmap vs VectorStore':<25} {'N/A':>25} {'SKIP':<10}\")\n",
        "else:\n",
        "    print(f\"{'Mmap vs VectorStore':<25} {r.get('speedup', 0):>20.1f}x faster {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# GWI vs HNSW\n",
        "r = RESULTS.get('gwi_vs_hnsw', {})\n",
        "if r.get('note'):\n",
        "    print(f\"{'GWI vs HNSW':<25} {'N/A':>25} {'SKIP':<10}\")\n",
        "else:\n",
        "    print(f\"{'GWI vs HNSW':<25} {r.get('speedup', 0):>20.1f}x faster {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# Recovery\n",
        "r = RESULTS.get('recovery', {})\n",
        "print(f\"{'Crash Recovery':<25} {'Integrity OK':>25} {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# Schema-Free\n",
        "r = RESULTS.get('schema_free', {})\n",
        "print(f\"{'Schema-Free Storage':<25} {str(r.get('types', 0)) + '/4 types':>25} {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "# Tensor\n",
        "r = RESULTS.get('tensor', {})\n",
        "print(f\"{'Tensor Extraction':<25} {str(r.get('count', 0)) + ' values':>25} {'PASS' if r.get('pass') else 'FAIL':<10}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Count results\n",
        "passed = sum(1 for r in RESULTS.values() if r.get('pass') is True)\n",
        "failed = sum(1 for r in RESULTS.values() if r.get('pass') is False)\n",
        "skipped = sum(1 for r in RESULTS.values() if r.get('pass') is None)\n",
        "total = passed + failed\n",
        "\n",
        "print(f\"TOTAL: {passed}/{total} benchmarks passed\")\n",
        "if skipped > 0:\n",
        "    print(f\"       {skipped} tests skipped (features not available)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nTip: Change SCALE to 'large' for more rigorous testing\")\n",
        "print(\"\\nLinks:\")\n",
        "print(\"  GitHub: https://github.com/gtava5813/SynaDB\")\n",
        "print(\"  PyPI:   pip install synadb\")"
      ],
      "metadata": {"id": "summary"},
      "execution_count": null,
      "outputs": []
    }
  ]
}